{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Dependency Installation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypots==0.8 in /usr/local/lib/python3.8/dist-packages (0.8)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from pypots==0.8) (2.4.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.8/dist-packages (from pypots==0.8) (3.8.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from pypots==0.8) (1.13.3)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.8/dist-packages (from pypots==0.8) (2.12.0)\n",
      "Requirement already satisfied: pygrinder>=0.6.4 in /usr/local/lib/python3.8/dist-packages (from pypots==0.8) (0.6.4)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.8/dist-packages (from pypots==0.8) (0.8.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from pypots==0.8) (2.0.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from pypots==0.8) (1.23.5)\n",
      "Requirement already satisfied: ai4ts in /usr/local/lib/python3.8/dist-packages (from pypots==0.8) (0.0.3)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from pypots==0.8) (1.10.1)\n",
      "Requirement already satisfied: tsdb>=0.6.1 in /usr/local/lib/python3.8/dist-packages (from pypots==0.8) (0.6.2)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.8/dist-packages (from pypots==0.8) (0.13.2)\n",
      "Requirement already satisfied: benchpots>=0.3 in /usr/local/lib/python3.8/dist-packages (from pypots==0.8) (0.3)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from pypots==0.8) (1.3.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from pypots==0.8) (3.7.5)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->pypots==0.8) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->pypots==0.8) (2.20.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->pypots==0.8) (3.1.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->pypots==0.8) (4.12.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->pypots==0.8) (12.1.105)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->pypots==0.8) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->pypots==0.8) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->pypots==0.8) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->pypots==0.8) (10.3.2.106)\n",
      "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->pypots==0.8) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->pypots==0.8) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->pypots==0.8) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->pypots==0.8) (11.4.5.107)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->pypots==0.8) (3.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->pypots==0.8) (3.16.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->pypots==0.8) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->pypots==0.8) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.8/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->pypots==0.8) (12.6.77)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from tsdb>=0.6.1->pypots==0.8) (4.66.6)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from tsdb>=0.6.1->pypots==0.8) (2.22.0)\n",
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.8/dist-packages (from tsdb>=0.6.1->pypots==0.8) (17.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pypots==0.8) (1.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pypots==0.8) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pypots==0.8) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pypots==0.8) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pypots==0.8) (3.1.4)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pypots==0.8) (6.4.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pypots==0.8) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pypots==0.8) (4.53.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pypots==0.8) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas->pypots==0.8) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.8/dist-packages (from pandas->pypots==0.8) (2024.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->pypots==0.8) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->pypots==0.8) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from sympy->pypots==0.8) (1.3.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard->pypots==0.8) (0.4.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->pypots==0.8) (67.6.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard->pypots==0.8) (1.51.3)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard->pypots==0.8) (2.2.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard->pypots==0.8) (2.16.2)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.8/dist-packages (from tensorboard->pypots==0.8) (4.22.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard->pypots==0.8) (1.4.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->pypots==0.8) (0.7.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard->pypots==0.8) (3.4.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->pypots==0.8) (1.8.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard->pypots==0.8) (0.40.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard->pypots==0.8) (1.14.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->pypots==0.8) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->pypots==0.8) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->pypots==0.8) (5.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->pypots==0.8) (1.3.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=3.2.0->matplotlib->pypots==0.8) (3.15.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard->pypots==0.8) (6.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=1.0.1->tensorboard->pypots==0.8) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->pypots==0.8) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->pypots==0.8) (3.2.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install pypots==0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Importando bibliotecas</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 21:36:49.928661: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "████████╗██╗███╗   ███╗███████╗    ███████╗███████╗██████╗ ██╗███████╗███████╗    █████╗ ██╗\n",
      "╚══██╔══╝██║████╗ ████║██╔════╝    ██╔════╝██╔════╝██╔══██╗██║██╔════╝██╔════╝   ██╔══██╗██║\n",
      "   ██║   ██║██╔████╔██║█████╗█████╗███████╗█████╗  ██████╔╝██║█████╗  ███████╗   ███████║██║\n",
      "   ██║   ██║██║╚██╔╝██║██╔══╝╚════╝╚════██║██╔══╝  ██╔══██╗██║██╔══╝  ╚════██║   ██╔══██║██║\n",
      "   ██║   ██║██║ ╚═╝ ██║███████╗    ███████║███████╗██║  ██║██║███████╗███████║██╗██║  ██║██║\n",
      "   ╚═╝   ╚═╝╚═╝     ╚═╝╚══════╝    ╚══════╝╚══════╝╚═╝  ╚═╝╚═╝╚══════╝╚══════╝╚═╝╚═╝  ╚═╝╚═╝\n",
      "ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pypots/nn/modules/reformer/local_attention.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled=False)\n",
      "/usr/local/lib/python3.8/dist-packages/pypots/nn/modules/reformer/local_attention.py:98: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled=False)\n"
     ]
    }
   ],
   "source": [
    "import pypots\n",
    "import numpy as np\n",
    "import benchpots\n",
    "from pypots.utils.random import set_random_seed\n",
    "from pypots.optim import Adam\n",
    "from pypots.imputation import BRITS\n",
    "from pypots.utils.metrics import calc_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Carregando base de dados</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 21:36:56 [INFO]: Have set the random seed as 2022 for numpy and pytorch.\n",
      "2024-12-03 21:36:56 [INFO]: You're using dataset physionet_2012, please cite it properly in your work. You can find its reference information at the below link: \n",
      "https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/physionet_2012\n",
      "2024-12-03 21:36:56 [INFO]: Dataset physionet_2012 has already been downloaded. Processing directly...\n",
      "2024-12-03 21:36:56 [INFO]: Dataset physionet_2012 has already been cached. Loading from cache directly...\n",
      "2024-12-03 21:36:56 [INFO]: Loaded successfully!\n",
      "2024-12-03 21:37:15 [WARNING]: Note that physionet_2012 has sparse observations in the time series, hence we don't add additional missing values to the training dataset. \n",
      "2024-12-03 21:37:16 [INFO]: 68807 values masked out in the val set as ground truth, take 9.97% of the original observed values\n",
      "2024-12-03 21:37:16 [INFO]: 86319 values masked out in the test set as ground truth, take 9.99% of the original observed values\n",
      "2024-12-03 21:37:16 [INFO]: Total sample number: 11988\n",
      "2024-12-03 21:37:16 [INFO]: Training set size: 7671 (63.99%)\n",
      "2024-12-03 21:37:16 [INFO]: Validation set size: 1918 (16.00%)\n",
      "2024-12-03 21:37:16 [INFO]: Test set size: 2399 (20.01%)\n",
      "2024-12-03 21:37:16 [INFO]: Number of steps: 48\n",
      "2024-12-03 21:37:16 [INFO]: Number of features: 37\n",
      "2024-12-03 21:37:16 [INFO]: Train set missing rate: 79.70%\n",
      "2024-12-03 21:37:16 [INFO]: Validating set missing rate: 81.75%\n",
      "2024-12-03 21:37:16 [INFO]: Test set missing rate: 81.75%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['n_classes', 'n_steps', 'n_features', 'scaler', 'train_X', 'train_y', 'train_ICUType', 'val_X', 'val_y', 'val_ICUType', 'test_X', 'test_y', 'test_ICUType', 'val_X_ori', 'test_X_ori'])\n"
     ]
    }
   ],
   "source": [
    "set_random_seed()\n",
    "\n",
    "# Load the PhysioNet-2012 dataset\n",
    "physionet2012_dataset = benchpots.datasets.preprocess_physionet2012(subset=\"all\", rate=0.1)\n",
    "\n",
    "# Take a look at the generated PhysioNet-2012 dataset, you'll find that everything has been prepared for you,\n",
    "# data splitting, normalization, additional artificially-missing values for evaluation, etc.\n",
    "print(physionet2012_dataset.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Separando datasets</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assemble the datasets for training\n",
    "dataset_for_training = {\n",
    "    \"X\": physionet2012_dataset['train_X'],\n",
    "}\n",
    "# assemble the datasets for validation\n",
    "dataset_for_validating = {\n",
    "    \"X\": physionet2012_dataset['val_X'],\n",
    "    \"X_ori\": physionet2012_dataset['val_X_ori'],\n",
    "}\n",
    "# assemble the datasets for test\n",
    "dataset_for_testing = {\n",
    "    \"X\": physionet2012_dataset['test_X'],\n",
    "}\n",
    "## calculate the mask to indicate the ground truth positions in test_X_ori, will be used by metric funcs to evaluate models\n",
    "test_X_indicating_mask = np.isnan(physionet2012_dataset['test_X_ori']) ^ np.isnan(physionet2012_dataset['test_X'])\n",
    "test_X_ori = np.nan_to_num(physionet2012_dataset['test_X_ori'])  # metric functions do not accpet input with NaNs, hence fill NaNs with 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Carregando modelo</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-24 22:36:11 [INFO]: No given device, using default device: cuda\n",
      "2024-11-24 22:36:11 [INFO]: Model files will be saved to tutorial_results/imputation/brits/20241124_T223611\n",
      "2024-11-24 22:36:11 [INFO]: Tensorboard file will be saved to tutorial_results/imputation/brits/20241124_T223611/tensorboard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-24 22:36:17 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 239,344\n"
     ]
    }
   ],
   "source": [
    "# initialize the model\n",
    "brits = BRITS(\n",
    "    n_steps=physionet2012_dataset['n_steps'],\n",
    "    n_features=physionet2012_dataset['n_features'],\n",
    "    rnn_hidden_size=128,\n",
    "    batch_size=32,\n",
    "    # here we set epochs=10 for a quick demo, you can set it to 100 or more for better performance\n",
    "    epochs=10,\n",
    "    # here we set patience=3 to early stop the training if the evaluting loss doesn't decrease for 3 epoches.\n",
    "    # You can leave it to defualt as None to disable early stopping.\n",
    "    patience=3,\n",
    "    # give the optimizer. Different from torch.optim.Optimizer, you don't have to specify model's parameters when\n",
    "    # initializing pypots.optim.Optimizer. You can also leave it to default. It will initilize an Adam optimizer with lr=0.001.\n",
    "    optimizer=Adam(lr=1e-3),\n",
    "    # this num_workers argument is for torch.utils.data.Dataloader. It's the number of subprocesses to use for data loading.\n",
    "    # Leaving it to default as 0 means data loading will be in the main process, i.e. there won't be subprocesses.\n",
    "    # You can increase it to >1 if you think your dataloading is a bottleneck to your model training speed\n",
    "    num_workers=0,\n",
    "    # just leave it to default as None, PyPOTS will automatically assign the best device for you.\n",
    "    # Set it as 'cpu' if you don't have CUDA devices. You can also set it to 'cuda:0' or 'cuda:1' if you have multiple CUDA devices, even parallelly on ['cuda:0', 'cuda:1']\n",
    "    device=None,\n",
    "    # set the path for saving tensorboard and trained model files\n",
    "    saving_path=\"tutorial_results/imputation/brits\",\n",
    "    # only save the best model after training finished.\n",
    "    # You can also set it as \"better\" to save models performing better ever during training.\n",
    "    model_saving_strategy=\"best\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Treinamento do modelo</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-24 15:50:32 [INFO]: Epoch 001 - training loss: 0.9418, validation loss: 6.7859\n",
      "2024-11-24 15:50:32 [INFO]: Saved the model to tutorial_results/imputation/brits/20241124_T154225/BRITS_epoch1_loss6.7859427854418755.pypots\n",
      "2024-11-24 15:57:53 [INFO]: Epoch 002 - training loss: 0.7343, validation loss: 6.7421\n",
      "2024-11-24 15:57:53 [INFO]: Saved the model to tutorial_results/imputation/brits/20241124_T154225/BRITS_epoch2_loss6.742129882673423.pypots\n",
      "2024-11-24 16:04:54 [INFO]: Epoch 003 - training loss: 0.6835, validation loss: 6.7306\n",
      "2024-11-24 16:04:54 [INFO]: Saved the model to tutorial_results/imputation/brits/20241124_T154225/BRITS_epoch3_loss6.730608933418989.pypots\n",
      "2024-11-24 16:11:15 [INFO]: Epoch 004 - training loss: 0.6591, validation loss: 6.7267\n",
      "2024-11-24 16:11:15 [INFO]: Saved the model to tutorial_results/imputation/brits/20241124_T154225/BRITS_epoch4_loss6.726703131943941.pypots\n",
      "2024-11-24 16:18:01 [INFO]: Epoch 005 - training loss: 0.6438, validation loss: 6.7250\n",
      "2024-11-24 16:18:01 [INFO]: Saved the model to tutorial_results/imputation/brits/20241124_T154225/BRITS_epoch5_loss6.725049399584532.pypots\n",
      "2024-11-24 16:25:18 [INFO]: Epoch 006 - training loss: 0.6324, validation loss: 6.7249\n",
      "2024-11-24 16:25:18 [INFO]: Saved the model to tutorial_results/imputation/brits/20241124_T154225/BRITS_epoch6_loss6.724923368791739.pypots\n",
      "2024-11-24 16:31:56 [INFO]: Epoch 007 - training loss: 0.6238, validation loss: 6.7277\n",
      "2024-11-24 16:38:57 [INFO]: Epoch 008 - training loss: 0.6161, validation loss: 6.7288\n",
      "2024-11-24 16:45:28 [INFO]: Epoch 009 - training loss: 0.6096, validation loss: 6.7307\n",
      "2024-11-24 16:45:28 [INFO]: Exceeded the training patience. Terminating the training procedure...\n",
      "2024-11-24 16:45:28 [INFO]: Finished training. The best model is from epoch#6.\n",
      "2024-11-24 16:45:28 [INFO]: Saved the model to tutorial_results/imputation/brits/20241124_T154225/BRITS.pypots\n"
     ]
    }
   ],
   "source": [
    "# train the model on the training set, and validate it on the validating set to select the best model for testing in the next step\n",
    "brits.fit(train_set=dataset_for_training, val_set=dataset_for_validating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pypots/base.py:324: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_model = torch.load(path, map_location=self.device)\n",
      "2024-11-24 22:36:29 [INFO]: Model loaded successfully from /data/victor/missingdata/notebooks/tutorial_results/imputation/brits/20241124_T154225/BRITS.pypots\n"
     ]
    }
   ],
   "source": [
    "brits.load('/data/victor/missingdata/notebooks/tutorial_results/imputation/brits/20241124_T154225/BRITS.pypots')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Imputação</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the testing stage, impute the originally-missing values and artificially-missing values in the test set\n",
    "brits_results = brits.predict(dataset_for_testing)\n",
    "brits_imputation = brits_results[\"imputation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Avaliação</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing mean absolute error: 0.2669\n"
     ]
    }
   ],
   "source": [
    "# calculate mean absolute error on the ground truth (artificially-missing values)\n",
    "testing_mae = calc_mae(\n",
    "    brits_imputation,\n",
    "    test_X_ori,\n",
    "    test_X_indicating_mask,\n",
    ")\n",
    "print(f\"Testing mean absolute error: {testing_mae:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
