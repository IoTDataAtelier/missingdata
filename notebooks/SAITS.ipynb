{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Dependency Installation<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypots==0.8\n",
      "  Downloading pypots-0.8-py3-none-any.whl (497 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m497.2/497.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from pypots==0.8) (1.3.2)\n",
      "Requirement already satisfied: tsdb>=0.6.1 in /usr/local/lib/python3.8/dist-packages (from pypots==0.8) (0.6.2)\n",
      "Collecting einops\n",
      "  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.8/dist-packages (from pypots==0.8) (2.12.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from pypots==0.8) (1.23.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from pypots==0.8) (1.10.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from pypots==0.8) (2.0.3)\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from pypots==0.8) (3.7.5)\n",
      "Collecting ai4ts\n",
      "  Downloading ai4ts-0.0.3-py3-none-any.whl (13 kB)\n",
      "Collecting benchpots>=0.3\n",
      "  Downloading benchpots-0.3-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from pypots==0.8) (2.4.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.8/dist-packages (from pypots==0.8) (3.8.0)\n",
      "Requirement already satisfied: pygrinder>=0.6.4 in /usr/local/lib/python3.8/dist-packages (from pypots==0.8) (0.6.4)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from pypots==0.8) (1.13.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->pypots==0.8) (4.12.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->pypots==0.8) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->pypots==0.8) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->pypots==0.8) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->pypots==0.8) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->pypots==0.8) (12.1.0.106)\n",
      "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->pypots==0.8) (3.0.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->pypots==0.8) (3.16.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->pypots==0.8) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->pypots==0.8) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->pypots==0.8) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->pypots==0.8) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->pypots==0.8) (2.20.5)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->pypots==0.8) (2024.10.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->pypots==0.8) (3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->pypots==0.8) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->pypots==0.8) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.8/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->pypots==0.8) (12.6.77)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from tsdb>=0.6.1->pypots==0.8) (2.22.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from tsdb>=0.6.1->pypots==0.8) (4.66.6)\n",
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.8/dist-packages (from tsdb>=0.6.1->pypots==0.8) (17.0.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pypots==0.8) (0.12.1)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pypots==0.8) (6.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pypots==0.8) (3.1.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pypots==0.8) (10.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pypots==0.8) (1.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pypots==0.8) (2.9.0.post0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pypots==0.8) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pypots==0.8) (23.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pypots==0.8) (4.53.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.8/dist-packages (from pandas->pypots==0.8) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas->pypots==0.8) (2024.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->pypots==0.8) (3.5.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->pypots==0.8) (1.4.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from sympy->pypots==0.8) (1.3.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard->pypots==0.8) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard->pypots==0.8) (2.2.3)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard->pypots==0.8) (0.40.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard->pypots==0.8) (3.4.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->pypots==0.8) (0.7.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard->pypots==0.8) (2.16.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->pypots==0.8) (67.6.0)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.8/dist-packages (from tensorboard->pypots==0.8) (4.22.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard->pypots==0.8) (1.8.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard->pypots==0.8) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard->pypots==0.8) (1.51.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->pypots==0.8) (4.9)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard->pypots==0.8) (1.14.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->pypots==0.8) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard->pypots==0.8) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->pypots==0.8) (1.3.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=3.2.0->matplotlib->pypots==0.8) (3.15.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard->pypots==0.8) (6.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=1.0.1->tensorboard->pypots==0.8) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->pypots==0.8) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->pypots==0.8) (3.2.2)\n",
      "Installing collected packages: einops, ai4ts, seaborn, benchpots, pypots\n",
      "Successfully installed ai4ts-0.0.3 benchpots-0.3 einops-0.8.0 pypots-0.8 seaborn-0.13.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install pypots==0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Importando o pypots<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-28 14:19:37.050643: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "████████╗██╗███╗   ███╗███████╗    ███████╗███████╗██████╗ ██╗███████╗███████╗    █████╗ ██╗\n",
      "╚══██╔══╝██║████╗ ████║██╔════╝    ██╔════╝██╔════╝██╔══██╗██║██╔════╝██╔════╝   ██╔══██╗██║\n",
      "   ██║   ██║██╔████╔██║█████╗█████╗███████╗█████╗  ██████╔╝██║█████╗  ███████╗   ███████║██║\n",
      "   ██║   ██║██║╚██╔╝██║██╔══╝╚════╝╚════██║██╔══╝  ██╔══██╗██║██╔══╝  ╚════██║   ██╔══██║██║\n",
      "   ██║   ██║██║ ╚═╝ ██║███████╗    ███████║███████╗██║  ██║██║███████╗███████║██╗██║  ██║██║\n",
      "   ╚═╝   ╚═╝╚═╝     ╚═╝╚══════╝    ╚══════╝╚══════╝╚═╝  ╚═╝╚═╝╚══════╝╚══════╝╚═╝╚═╝  ╚═╝╚═╝\n",
      "ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pypots/nn/modules/reformer/local_attention.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled=False)\n",
      "/usr/local/lib/python3.8/dist-packages/pypots/nn/modules/reformer/local_attention.py:98: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled=False)\n"
     ]
    }
   ],
   "source": [
    "import pypots\n",
    "from pypots.utils.metrics import calc_mae\n",
    "from pypots.optim import Adam\n",
    "from pypots.imputation import SAITS\n",
    "import numpy as np\n",
    "import benchpots\n",
    "from pypots.utils.random import set_random_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h3>Preparing the PhysioNet-2012 dataset for this tutorial<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-28 14:19:40 [INFO]: Have set the random seed as 2022 for numpy and pytorch.\n",
      "2024-11-28 14:19:40 [INFO]: You're using dataset physionet_2012, please cite it properly in your work. You can find its reference information at the below link: \n",
      "https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/physionet_2012\n",
      "2024-11-28 14:19:40 [INFO]: Dataset physionet_2012 has already been downloaded. Processing directly...\n",
      "2024-11-28 14:19:40 [INFO]: Dataset physionet_2012 has already been cached. Loading from cache directly...\n",
      "2024-11-28 14:19:41 [INFO]: Loaded successfully!\n",
      "2024-11-28 14:19:59 [WARNING]: Note that physionet_2012 has sparse observations in the time series, hence we don't add additional missing values to the training dataset. \n",
      "2024-11-28 14:19:59 [INFO]: 68807 values masked out in the val set as ground truth, take 9.97% of the original observed values\n",
      "2024-11-28 14:19:59 [INFO]: 86319 values masked out in the test set as ground truth, take 9.99% of the original observed values\n",
      "2024-11-28 14:19:59 [INFO]: Total sample number: 11988\n",
      "2024-11-28 14:19:59 [INFO]: Training set size: 7671 (63.99%)\n",
      "2024-11-28 14:19:59 [INFO]: Validation set size: 1918 (16.00%)\n",
      "2024-11-28 14:19:59 [INFO]: Test set size: 2399 (20.01%)\n",
      "2024-11-28 14:19:59 [INFO]: Number of steps: 48\n",
      "2024-11-28 14:19:59 [INFO]: Number of features: 37\n",
      "2024-11-28 14:19:59 [INFO]: Train set missing rate: 79.70%\n",
      "2024-11-28 14:19:59 [INFO]: Validating set missing rate: 81.75%\n",
      "2024-11-28 14:19:59 [INFO]: Test set missing rate: 81.75%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['n_classes', 'n_steps', 'n_features', 'scaler', 'train_X', 'train_y', 'train_ICUType', 'val_X', 'val_y', 'val_ICUType', 'test_X', 'test_y', 'test_ICUType', 'val_X_ori', 'test_X_ori'])\n"
     ]
    }
   ],
   "source": [
    "set_random_seed()\n",
    "\n",
    "# Load the PhysioNet-2012 dataset\n",
    "physionet2012_dataset = benchpots.datasets.preprocess_physionet2012(subset=\"all\", rate=0.1)\n",
    "\n",
    "# Take a look at the generated PhysioNet-2012 dataset, you'll find that everything has been prepared for you,\n",
    "# data splitting, normalization, additional artificially-missing values for evaluation, etc.\n",
    "print(physionet2012_dataset.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Imputation Models<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assemble the datasets for training\n",
    "dataset_for_training = {\n",
    "    \"X\": physionet2012_dataset['train_X'],\n",
    "}\n",
    "# assemble the datasets for validation\n",
    "dataset_for_validating = {\n",
    "    \"X\": physionet2012_dataset['val_X'],\n",
    "    \"X_ori\": physionet2012_dataset['val_X_ori'],\n",
    "}\n",
    "# assemble the datasets for test\n",
    "dataset_for_testing = {\n",
    "    \"X\": physionet2012_dataset['test_X'],\n",
    "}\n",
    "## calculate the mask to indicate the ground truth positions in test_X_ori, will be used by metric funcs to evaluate models\n",
    "test_X_indicating_mask = np.isnan(physionet2012_dataset['test_X_ori']) ^ np.isnan(physionet2012_dataset['test_X'])\n",
    "test_X_ori = np.nan_to_num(physionet2012_dataset['test_X_ori'])  # metric functions do not accpet input with NaNs, hence fill NaNs with 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>An example of SAITS for imputation<h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Initialize the model<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-28 14:20:15 [INFO]: No given device, using default device: cpu\n",
      "2024-11-28 14:20:15 [INFO]: Model files will be saved to tutorial_results/imputation/saits/20241128_T142015\n",
      "2024-11-28 14:20:15 [INFO]: Tensorboard file will be saved to tutorial_results/imputation/saits/20241128_T142015/tensorboard\n",
      "2024-11-28 14:20:15 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 720,182\n"
     ]
    }
   ],
   "source": [
    "# initialize the model\n",
    "saits = SAITS(\n",
    "    n_steps=physionet2012_dataset['n_steps'],\n",
    "    n_features=physionet2012_dataset['n_features'],\n",
    "    n_layers=1,\n",
    "    d_model=256,\n",
    "    d_ffn=128,\n",
    "    n_heads=4,\n",
    "    d_k=64,\n",
    "    d_v=64,\n",
    "    dropout=0.1,\n",
    "    ORT_weight=1,  # you can adjust the weight values of arguments ORT_weight\n",
    "    # and MIT_weight to make the SAITS model focus more on one task. Usually you can just leave them to the default values, i.e. 1.\n",
    "    MIT_weight=1,\n",
    "    batch_size=32,\n",
    "    # here we set epochs=10 for a quick demo, you can set it to 100 or more for better performance\n",
    "    epochs=10,\n",
    "    # here we set patience=3 to early stop the training if the evaluting loss doesn't decrease for 3 epoches.\n",
    "    # You can leave it to defualt as None to disable early stopping.\n",
    "    patience=3,\n",
    "    # give the optimizer. Different from torch.optim.Optimizer, you don't have to specify model's parameters when\n",
    "    # initializing pypots.optim.Optimizer. You can also leave it to default. It will initilize an Adam optimizer with lr=0.001.\n",
    "    optimizer=Adam(lr=1e-3),\n",
    "    # this num_workers argument is for torch.utils.data.Dataloader. It's the number of subprocesses to use for data loading.\n",
    "    # Leaving it to default as 0 means data loading will be in the main process, i.e. there won't be subprocesses.\n",
    "    # You can increase it to >1 if you think your dataloading is a bottleneck to your model training speed\n",
    "    num_workers=0,\n",
    "    # just leave it to default as None, PyPOTS will automatically assign the best device for you.\n",
    "    # Set it as 'cpu' if you don't have CUDA devices. You can also set it to 'cuda:0' or 'cuda:1' if you have multiple CUDA devices, even parallelly on ['cuda:0', 'cuda:1']\n",
    "    device=None,\n",
    "    # set the path for saving tensorboard and trained model files\n",
    "    saving_path=\"tutorial_results/imputation/saits\",\n",
    "    # only save the best model after training finished.\n",
    "    # You can also set it as \"better\" to save models performing better ever during training.\n",
    "    model_saving_strategy=\"best\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Train the model<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 11:56:45 [INFO]: Epoch 001 - training loss: 0.7230, validation loss: 6.7596\n",
      "2024-11-18 11:56:45 [INFO]: Saved the model to tutorial_results/imputation/saits/20241118_T115553/SAITS_epoch1_loss6.75964179734389.pypots\n",
      "2024-11-18 11:57:10 [INFO]: Epoch 002 - training loss: 0.5370, validation loss: 6.7420\n",
      "2024-11-18 11:57:10 [INFO]: Saved the model to tutorial_results/imputation/saits/20241118_T115553/SAITS_epoch2_loss6.741982015470664.pypots\n",
      "2024-11-18 11:57:38 [INFO]: Epoch 003 - training loss: 0.4953, validation loss: 6.7242\n",
      "2024-11-18 11:57:38 [INFO]: Saved the model to tutorial_results/imputation/saits/20241118_T115553/SAITS_epoch3_loss6.724190835654736.pypots\n",
      "2024-11-18 11:58:06 [INFO]: Epoch 004 - training loss: 0.4641, validation loss: 6.7040\n",
      "2024-11-18 11:58:06 [INFO]: Saved the model to tutorial_results/imputation/saits/20241118_T115553/SAITS_epoch4_loss6.703969217836857.pypots\n",
      "2024-11-18 11:58:32 [INFO]: Epoch 005 - training loss: 0.4387, validation loss: 6.6843\n",
      "2024-11-18 11:58:32 [INFO]: Saved the model to tutorial_results/imputation/saits/20241118_T115553/SAITS_epoch5_loss6.68434986770153.pypots\n",
      "2024-11-18 11:59:01 [INFO]: Epoch 006 - training loss: 0.4206, validation loss: 6.6695\n",
      "2024-11-18 11:59:01 [INFO]: Saved the model to tutorial_results/imputation/saits/20241118_T115553/SAITS_epoch6_loss6.669484475751718.pypots\n",
      "2024-11-18 11:59:31 [INFO]: Epoch 007 - training loss: 0.4065, validation loss: 6.6588\n",
      "2024-11-18 11:59:31 [INFO]: Saved the model to tutorial_results/imputation/saits/20241118_T115553/SAITS_epoch7_loss6.6587558100620905.pypots\n",
      "2024-11-18 11:59:55 [INFO]: Epoch 008 - training loss: 0.3963, validation loss: 6.6534\n",
      "2024-11-18 11:59:55 [INFO]: Saved the model to tutorial_results/imputation/saits/20241118_T115553/SAITS_epoch8_loss6.653379916523893.pypots\n",
      "2024-11-18 12:00:22 [INFO]: Epoch 009 - training loss: 0.3867, validation loss: 6.6520\n",
      "2024-11-18 12:00:22 [INFO]: Saved the model to tutorial_results/imputation/saits/20241118_T115553/SAITS_epoch9_loss6.652013070633014.pypots\n",
      "2024-11-18 12:00:47 [INFO]: Epoch 010 - training loss: 0.3793, validation loss: 6.6574\n",
      "2024-11-18 12:00:47 [INFO]: Finished training. The best model is from epoch#9.\n",
      "2024-11-18 12:00:47 [INFO]: Saved the model to tutorial_results/imputation/saits/20241118_T115553/SAITS.pypots\n"
     ]
    }
   ],
   "source": [
    "# train the model on the training set, and validate it on the validating set to select the best model for testing in the next step\n",
    "saits.fit(train_set=dataset_for_training, val_set=dataset_for_validating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pypots/base.py:324: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_model = torch.load(path, map_location=self.device)\n",
      "2024-11-28 14:20:20 [INFO]: Model loaded successfully from /data/rayssa/missingdata/tutorial_results/imputation/saits/20241124_T223952/SAITS.pypots\n"
     ]
    }
   ],
   "source": [
    "saits.load('/data/rayssa/missingdata/tutorial_results/imputation/saits/20241124_T223952/SAITS.pypots')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> The testing stage <h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the testing stage, impute the originally-missing values and artificially-missing values in the test set\n",
    "saits_results = saits.predict(dataset_for_testing)\n",
    "saits_imputation = saits_results[\"imputation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Calculate mean absolute error <h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing mean absolute error: 0.2458\n"
     ]
    }
   ],
   "source": [
    "# calculate mean absolute error on the ground truth (artificially-missing values)\n",
    "testing_mae = calc_mae(\n",
    "    saits_imputation,\n",
    "    test_X_ori,\n",
    "    test_X_indicating_mask,\n",
    ")\n",
    "print(f\"Testing mean absolute error: {testing_mae:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
