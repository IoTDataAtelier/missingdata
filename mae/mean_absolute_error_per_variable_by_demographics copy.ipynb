{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-01 11:11:12.724338: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-01 11:11:12.739244: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-01 11:11:12.743824: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-01 11:11:12.755850: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "████████╗██╗███╗   ███╗███████╗    ███████╗███████╗██████╗ ██╗███████╗███████╗    █████╗ ██╗\n",
      "╚══██╔══╝██║████╗ ████║██╔════╝    ██╔════╝██╔════╝██╔══██╗██║██╔════╝██╔════╝   ██╔══██╗██║\n",
      "   ██║   ██║██╔████╔██║█████╗█████╗███████╗█████╗  ██████╔╝██║█████╗  ███████╗   ███████║██║\n",
      "   ██║   ██║██║╚██╔╝██║██╔══╝╚════╝╚════██║██╔══╝  ██╔══██╗██║██╔══╝  ╚════██║   ██╔══██║██║\n",
      "   ██║   ██║██║ ╚═╝ ██║███████╗    ███████║███████╗██║  ██║██║███████╗███████║██╗██║  ██║██║\n",
      "   ╚═╝   ╚═╝╚═╝     ╚═╝╚══════╝    ╚══════╝╚══════╝╚═╝  ╚═╝╚═╝╚══════╝╚══════╝╚═╝╚═╝  ╚═╝╚═╝\n",
      "ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pypots/nn/modules/reformer/local_attention.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled=False)\n",
      "/usr/local/lib/python3.11/dist-packages/pypots/nn/modules/reformer/local_attention.py:98: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled=False)\n"
     ]
    }
   ],
   "source": [
    "import pypots\n",
    "import os\n",
    "import sys\n",
    "from pypots.utils.metrics import calc_mae\n",
    "from pypots.optim import Adam\n",
    "from pypots.imputation import SAITS, BRITS\n",
    "import numpy as np\n",
    "import benchpots\n",
    "from pypots.utils.random import set_random_seed\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-01 11:11:16 [INFO]: Have set the random seed as 2022 for numpy and pytorch.\n",
      "2025-02-01 11:11:16 [INFO]: You're using dataset physionet_2012, please cite it properly in your work. You can find its reference information at the below link: \n",
      "https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/physionet_2012\n",
      "2025-02-01 11:11:16 [INFO]: Dataset physionet_2012 has already been downloaded. Processing directly...\n",
      "2025-02-01 11:11:16 [INFO]: Dataset physionet_2012 has already been cached. Loading from cache directly...\n",
      "2025-02-01 11:11:16 [INFO]: Loaded successfully!\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Gender'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Gender'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpypotsModify\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbenchpotsMAE\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m preprocess_physionet2012\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Load the PhysioNet-2012 dataset\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m physionet2012_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_physionet2012\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mall\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Take a look at the generated PhysioNet-2012 dataset, you'll find that everything has been prepared for you,\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# data splitting, normalization, additional artificially-missing values for evaluation, etc.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(physionet2012_dataset\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[0;32m/data/rayssa/missingdata/pypotsModify/benchpotsMAE/datasets/physionet_2012.py:150\u001b[0m, in \u001b[0;36mpreprocess_physionet2012\u001b[0;34m(subset, rate, pattern, features, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m test_set \u001b[38;5;241m=\u001b[39m X[X[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecordID\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misin(test_set_ids)]\u001b[38;5;241m.\u001b[39msort_values([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecordID\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m#dividir o conjunto de teste nos subgrupos\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m#Divisão por gênero\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m female_gender_test_ids \u001b[38;5;241m=\u001b[39m test_set[\u001b[43mtest_set\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGender\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m]\n\u001b[1;32m    151\u001b[0m female_gender_test_ids  \u001b[38;5;241m=\u001b[39m female_gender_test_ids[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecordID\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    152\u001b[0m female_gender_test \u001b[38;5;241m=\u001b[39m test_set[test_set[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecordID\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misin(female_gender_test_ids)]\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Gender'"
     ]
    }
   ],
   "source": [
    "set_random_seed()\n",
    "\n",
    "from pypotsModify.benchpotsMAE.datasets import preprocess_physionet2012\n",
    "\n",
    "# Load the PhysioNet-2012 dataset\n",
    "physionet2012_dataset = preprocess_physionet2012(subset=\"all\", rate=0.1)\n",
    "\n",
    "# Take a look at the generated PhysioNet-2012 dataset, you'll find that everything has been prepared for you,\n",
    "# data splitting, normalization, additional artificially-missing values for evaluation, etc.\n",
    "print(physionet2012_dataset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assemble the datasets for training\n",
    "dataset_for_training = {\n",
    "    \"X\": physionet2012_dataset['train_X'],\n",
    "}\n",
    "# assemble the datasets for validation\n",
    "dataset_for_validating = {\n",
    "    \"X\": physionet2012_dataset['val_X'],\n",
    "    \"X_ori\": physionet2012_dataset['val_X_ori'],\n",
    "}\n",
    "\n",
    "dataset_for_testing_ori = {\n",
    "    \"X_ori\": physionet2012_dataset['test_X_ori'],\n",
    "    \"female_gender_test_X_ori\": physionet2012_dataset['female_gender_test_X_ori'],\n",
    "    \"male_gender_test_X_ori\": physionet2012_dataset['male_gender_test_X_ori'],\n",
    "    \"undefined_gender_test_X_ori\": physionet2012_dataset['undefined_gender_test_X_ori'],\n",
    "    \"more_than_or_equal_to_65_test_X_ori\":  physionet2012_dataset['more_than_or_equal_to_65_test_X_ori'],\n",
    "    \"less_than_65_test_X_ori\": physionet2012_dataset['less_than_65_test_X_ori'],\n",
    "    \"ICUType_1_test_X_ori\": physionet2012_dataset['ICUType_1_test_X_ori'],\n",
    "    \"ICUType_2_test_X_ori\": physionet2012_dataset['ICUType_2_test_X_ori'],\n",
    "    \"ICUType_3_test_X_ori\": physionet2012_dataset['ICUType_3_test_X_ori'],\n",
    "    \"ICUType_4_test_X_ori\": physionet2012_dataset['ICUType_4_test_X_ori'],\n",
    "    \"classificacao_undefined_test_X_ori\": physionet2012_dataset['classificacao_undefined_test_X_ori'],\n",
    "    \"classificacao_baixo_peso_test_X_ori\": physionet2012_dataset['classificacao_baixo_peso_test_X_ori'],\n",
    "    \"classificacao_normal_peso_test_X_ori\": physionet2012_dataset['classificacao_normal_peso_test_X_ori'],\n",
    "    \"classificacao_sobrepeso_test_X_ori\": physionet2012_dataset['classificacao_sobrepeso_test_X_ori'],\n",
    "    \"classificacao_obesidade_1_test_X_ori\": physionet2012_dataset['classificacao_obesidade_1_test_X_ori'],\n",
    "    \"classificacao_obesidade_2_test_X_ori\": physionet2012_dataset['classificacao_obesidade_2_test_X_ori'],\n",
    "    \"classificacao_obesidade_3_test_X_ori\": physionet2012_dataset['classificacao_obesidade_3_test_X_ori']\n",
    "}\n",
    "\n",
    "# assemble the datasets for test\n",
    "dataset_for_testing = {\n",
    "    \"X\": physionet2012_dataset['test_X'],\n",
    "    \"female_gender_test_X\": physionet2012_dataset['female_gender_test_X'],\n",
    "    \"male_gender_test_X\": physionet2012_dataset['male_gender_test_X'],\n",
    "    \"undefined_gender_test_X\": physionet2012_dataset['undefined_gender_test_X'],\n",
    "    \"more_than_or_equal_to_65_test_X\":  physionet2012_dataset['more_than_or_equal_to_65_test_X'],\n",
    "    \"less_than_65_test_X\": physionet2012_dataset['less_than_65_test_X'],\n",
    "    \"ICUType_1_test_X\": physionet2012_dataset['ICUType_1_test_X'],\n",
    "    \"ICUType_2_test_X\": physionet2012_dataset['ICUType_2_test_X'],\n",
    "    \"ICUType_3_test_X\": physionet2012_dataset['ICUType_3_test_X'],\n",
    "    \"ICUType_4_test_X\": physionet2012_dataset['ICUType_4_test_X'],\n",
    "    \"classificacao_undefined_test_X\": physionet2012_dataset['classificacao_undefined_test_X'],\n",
    "    \"classificacao_baixo_peso_test_X\": physionet2012_dataset['classificacao_baixo_peso_test_X'],\n",
    "    \"classificacao_normal_peso_test_X\": physionet2012_dataset['classificacao_normal_peso_test_X'],\n",
    "    \"classificacao_sobrepeso_test_X\": physionet2012_dataset['classificacao_sobrepeso_test_X'],\n",
    "    \"classificacao_obesidade_1_test_X\": physionet2012_dataset['classificacao_obesidade_1_test_X'],\n",
    "    \"classificacao_obesidade_2_test_X\": physionet2012_dataset['classificacao_obesidade_2_test_X'],\n",
    "    \"classificacao_obesidade_3_test_X\": physionet2012_dataset['classificacao_obesidade_3_test_X']\n",
    "}\n",
    "\n",
    "## calculate the mask to indicate the ground truth positions in test_X_ori, will be used by metric funcs to evaluate models\n",
    "test_X_indicating_mask = []\n",
    "test_X_ori = []\n",
    "for i, j in zip(dataset_for_testing_ori.values(), dataset_for_testing.values()):\n",
    "    test_X_indicating_mask.append(np.isnan(i) ^ np.isnan(j))\n",
    "    test_X_ori.append(np.nan_to_num(i))# metric functions do not accpet input with NaNs, hence fill NaNs with 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X_indicating_mask_variable = []\n",
    "test_X_ori_variable = []\n",
    "for i in range(len(test_X_indicating_mask)):\n",
    "    test_X_indicating_mask_variable.append(test_X_indicating_mask[i].reshape(42, len(test_X_indicating_mask[i]) * 48))\n",
    "    test_X_ori_variable.append(test_X_ori[i].reshape(42, len(test_X_ori[i]) * 48))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicialize the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-01 09:33:59 [INFO]: No given device, using default device: cuda\n",
      "2025-02-01 09:33:59 [INFO]: Model files will be saved to tutorial_results/imputation/saits/20250201_T093359\n",
      "2025-02-01 09:33:59 [INFO]: Tensorboard file will be saved to tutorial_results/imputation/saits/20250201_T093359/tensorboard\n",
      "2025-02-01 09:33:59 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 728,912\n"
     ]
    }
   ],
   "source": [
    "saits = SAITS(\n",
    "    n_steps=physionet2012_dataset['n_steps'],\n",
    "    n_features=physionet2012_dataset['n_features'],\n",
    "    n_layers=1,\n",
    "    d_model=256,\n",
    "    d_ffn=128,\n",
    "    n_heads=4,\n",
    "    d_k=64,\n",
    "    d_v=64,\n",
    "    dropout=0.1,\n",
    "    ORT_weight=1,  # you can adjust the weight values of arguments ORT_weight\n",
    "    # and MIT_weight to make the SAITS model focus more on one task. Usually you can just leave them to the default values, i.e. 1.\n",
    "    MIT_weight=1,\n",
    "    batch_size=32,\n",
    "    # here we set epochs=10 for a quick demo, you can set it to 100 or more for better performance\n",
    "    epochs=10,\n",
    "    # here we set patience=3 to early stop the training if the evaluting loss doesn't decrease for 3 epoches.\n",
    "    # You can leave it to defualt as None to disable early stopping.\n",
    "    patience=3,\n",
    "    # give the optimizer. Different from torch.optim.Optimizer, you don't have to specify model's parameters when\n",
    "    # initializing pypots.optim.Optimizer. You can also leave it to default. It will initilize an Adam optimizer with lr=0.001.\n",
    "    optimizer=Adam(lr=1e-3),\n",
    "    # this num_workers argument is for torch.utils.data.Dataloader. It's the number of subprocesses to use for data loading.\n",
    "    # Leaving it to default as 0 means data loading will be in the main process, i.e. there won't be subprocesses.\n",
    "    # You can increase it to >1 if you think your dataloading is a bottleneck to your model training speed\n",
    "    num_workers=0,\n",
    "    # just leave it to default as None, PyPOTS will automatically assign the best device for you.\n",
    "    # Set it as 'cpu' if you don't have CUDA devices. You can also set it to 'cuda:0' or 'cuda:1' if you have multiple CUDA devices, even parallelly on ['cuda:0', 'cuda:1']\n",
    "    device=None,\n",
    "    # set the path for saving tensorboard and trained model files\n",
    "    saving_path=\"tutorial_results/imputation/saits\",\n",
    "    # only save the best model after training finished.\n",
    "    # You can also set it as \"better\" to save models performing better ever during training.\n",
    "    model_saving_strategy=\"best\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-01 09:34:02 [INFO]: No given device, using default device: cuda\n",
      "2025-02-01 09:34:02 [INFO]: Model files will be saved to tutorial_results/imputation/brits/20250201_T093402\n",
      "2025-02-01 09:34:02 [INFO]: Tensorboard file will be saved to tutorial_results/imputation/brits/20250201_T093402/tensorboard\n",
      "2025-02-01 09:34:02 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 255,344\n"
     ]
    }
   ],
   "source": [
    "brits = BRITS(\n",
    "    n_steps=physionet2012_dataset['n_steps'],\n",
    "    n_features=physionet2012_dataset['n_features'],\n",
    "    rnn_hidden_size=128,\n",
    "    batch_size=32,\n",
    "    # here we set epochs=10 for a quick demo, you can set it to 100 or more for better performance\n",
    "    epochs=10,\n",
    "    # here we set patience=3 to early stop the training if the evaluting loss doesn't decrease for 3 epoches.\n",
    "    # You can leave it to defualt as None to disable early stopping.\n",
    "    patience=3,\n",
    "    # give the optimizer. Different from torch.optim.Optimizer, you don't have to specify model's parameters when\n",
    "    # initializing pypots.optim.Optimizer. You can also leave it to default. It will initilize an Adam optimizer with lr=0.001.\n",
    "    optimizer=Adam(lr=1e-3),\n",
    "    # this num_workers argument is for torch.utils.data.Dataloader. It's the number of subprocesses to use for data loading.\n",
    "    # Leaving it to default as 0 means data loading will be in the main process, i.e. there won't be subprocesses.\n",
    "    # You can increase it to >1 if you think your dataloading is a bottleneck to your model training speed\n",
    "    num_workers=0,\n",
    "    # just leave it to default as None, PyPOTS will automatically assign the best device for you.\n",
    "    # Set it as 'cpu' if you don't have CUDA devices. You can also set it to 'cuda:0' or 'cuda:1' if you have multiple CUDA devices, even parallelly on ['cuda:0', 'cuda:1']\n",
    "    device=None,\n",
    "    # set the path for saving tensorboard and trained model files\n",
    "    saving_path=\"tutorial_results/imputation/brits\",\n",
    "    # only save the best model after training finished.\n",
    "    # You can also set it as \"better\" to save models performing better ever during training.\n",
    "    model_saving_strategy=\"best\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-01 09:34:08 [INFO]: Epoch 001 - training loss: 0.6432, validation loss: 0.2715\n",
      "2025-02-01 09:34:11 [INFO]: Epoch 002 - training loss: 0.4508, validation loss: 0.2529\n",
      "2025-02-01 09:34:13 [INFO]: Epoch 003 - training loss: 0.4169, validation loss: 0.2287\n",
      "2025-02-01 09:34:16 [INFO]: Epoch 004 - training loss: 0.3925, validation loss: 0.2156\n",
      "2025-02-01 09:34:19 [INFO]: Epoch 005 - training loss: 0.3743, validation loss: 0.2076\n",
      "2025-02-01 09:34:22 [INFO]: Epoch 006 - training loss: 0.3599, validation loss: 0.1973\n",
      "2025-02-01 09:34:25 [INFO]: Epoch 007 - training loss: 0.3488, validation loss: 0.1952\n",
      "2025-02-01 09:34:27 [INFO]: Epoch 008 - training loss: 0.3406, validation loss: 0.1884\n",
      "2025-02-01 09:34:30 [INFO]: Epoch 009 - training loss: 0.3327, validation loss: 0.1857\n",
      "2025-02-01 09:34:33 [INFO]: Epoch 010 - training loss: 0.3261, validation loss: 0.1829\n",
      "2025-02-01 09:34:33 [INFO]: Finished training. The best model is from epoch#10.\n",
      "2025-02-01 09:34:33 [INFO]: Saved the model to tutorial_results/imputation/saits/20250201_T093359/SAITS.pypots\n"
     ]
    }
   ],
   "source": [
    "# train the model on the training set, and validate it on the validating set to select the best model for testing in the next step\n",
    "saits.fit(train_set=dataset_for_training, val_set=dataset_for_validating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-01 09:36:59 [INFO]: Epoch 001 - training loss: 0.8452, validation loss: 0.2879\n",
      "2025-02-01 09:37:49 [INFO]: Epoch 002 - training loss: 0.5927, validation loss: 0.2551\n",
      "2025-02-01 09:38:37 [INFO]: Epoch 003 - training loss: 0.5456, validation loss: 0.2422\n",
      "2025-02-01 09:39:25 [INFO]: Epoch 004 - training loss: 0.5236, validation loss: 0.2378\n",
      "2025-02-01 09:40:14 [INFO]: Epoch 005 - training loss: 0.5097, validation loss: 0.2318\n",
      "2025-02-01 09:41:03 [INFO]: Epoch 006 - training loss: 0.4991, validation loss: 0.2319\n",
      "2025-02-01 09:41:50 [INFO]: Epoch 007 - training loss: 0.4900, validation loss: 0.2305\n",
      "2025-02-01 09:42:37 [INFO]: Epoch 008 - training loss: 0.4827, validation loss: 0.2317\n",
      "2025-02-01 09:43:25 [INFO]: Epoch 009 - training loss: 0.4765, validation loss: 0.2358\n",
      "2025-02-01 09:44:12 [INFO]: Epoch 010 - training loss: 0.4718, validation loss: 0.2394\n",
      "2025-02-01 09:44:12 [INFO]: Exceeded the training patience. Terminating the training procedure...\n",
      "2025-02-01 09:44:12 [INFO]: Finished training. The best model is from epoch#7.\n",
      "2025-02-01 09:44:12 [INFO]: Saved the model to tutorial_results/imputation/brits/20250201_T093402/BRITS.pypots\n"
     ]
    }
   ],
   "source": [
    "# train the model on the training set, and validate it on the validating set to select the best model for testing in the next step\n",
    "brits.fit(train_set=dataset_for_training, val_set=dataset_for_validating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The testing stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the testing stage, impute the originally-missing values and artificially-missing values in the test set\n",
    "saits_imputation = []\n",
    "for value in  dataset_for_testing.values():\n",
    "   _dict = {'X':value}\n",
    "   saits_results = saits.predict(_dict)\n",
    "   saits_imputation.append(saits_results[\"imputation\"])  \n",
    "\n",
    "teste = 'Teste'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "saits_imputation_variable = []\n",
    "for i in range(len(saits_imputation)):\n",
    "    saits_imputation_variable.append(saits_imputation[i].reshape(42, len(saits_imputation[i]) * 48))\n",
    "\n",
    "teste = 'Teste'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the testing stage, impute the originally-missing values and artificially-missing values in the test set\n",
    "brits_imputation = []\n",
    "for value in dataset_for_testing.values():\n",
    "    _dict = {'X':value}\n",
    "    brits_results = brits.predict(_dict)\n",
    "    brits_imputation.append(brits_results[\"imputation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "brits_imputation_variable = []\n",
    "for i in range(len(brits_imputation)):\n",
    "    brits_imputation_variable.append(brits_imputation[i].reshape(42, len(brits_imputation[i]) * 48))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate mean absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_mae_saits_append_subgroups = []\n",
    "testing_mae_saits_append_variables = []\n",
    "for i in range(len(saits_imputation_variable)):\n",
    "    for j in range(len(saits_imputation_variable[i])):\n",
    "        testing_mae_saits_append_variables.append(calc_mae(saits_imputation_variable[i][j], test_X_ori_variable[i][j], test_X_indicating_mask_variable[i][j]))\n",
    "    testing_mae_saits_append_subgroups.append(testing_mae_saits_append_variables)\n",
    "    testing_mae_saits_append_variables = []\n",
    "Teste = 'Teste'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115152"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(saits_imputation_variable[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.6963346 , -0.25993752, -0.28740552, ..., -0.50364804,\n",
       "        0.06673649,  0.50916517], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saits_imputation_variable[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_mae_brits_append_subgroups = []\n",
    "testing_mae_brits_append_variables = []\n",
    "for i in range(len(brits_imputation_variable)):\n",
    "    for j in range(len(brits_imputation_variable[i])):\n",
    "      testing_mae_brits_append_variables.append(calc_mae(brits_imputation_variable[i][j], test_X_ori_variable[i][j], test_X_indicating_mask_variable[i][j]))\n",
    "    testing_mae_brits_append_subgroups.append(testing_mae_brits_append_variables)\n",
    "    testing_mae_brits_append_variables = []\n",
    "Teste = 'Teste'      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgroups = [\"General\", \"Female\", \"Male\", \"Undefined Gender\", \"+65\", \"-65\", \"ICUType 1\", \"ICUType 2\", \"ICUType 3\", \"ICUType 4\", \"Undefined classification\", \"Low Weight\", \"Normal Weight\", \"Overweight\", \"Obesity 1\", \"Obesity 2\", \"Obesity 3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAITS - MAE\n",
      "-------------\n",
      "General : [0.19572739440498355, 0.20853521315798965, 0.19487407430090256, 0.2073061049144169, 0.1944357658739892, 0.19746742090645422, 0.20486614316802926, 0.22529100555207046, 0.22139870441860618, 0.21851921382191167, 0.2119795299471394, 0.20970293554553535, 0.2237109275175156, 0.19812710101598188, 0.1969537153823656, 0.1950228074439476, 0.20598885165151418, 0.21394210304939348, 0.20018607734232366, 0.20055161716443498, 0.18794757082124236, 0.21822586951340053, 0.19192918982805554, 0.19728892568022047, 0.19225807179554388, 0.2029464349340934, 0.21613127433775006, 0.19780547715775146, 0.20746290177883583, 0.19489771802802275, 0.20875520967241484, 0.20989458246066348, 0.21454475577605597, 0.202597888736192, 0.1962651487012549, 0.1985894046155526, 0.19656423254722666, 0.21395801079093715, 0.20067152306791095, 0.21295627724084598, 0.2009485002710331, 0.21180076670475223]\n",
      "Female : [0.18286259372835592, 0.19643363068126918, 0.1982360345010649, 0.23486070362116754, 0.1992629160913167, 0.19746650684856054, 0.19467068988899985, 0.1920176270262605, 0.2243589728117428, 0.1970130587817416, 0.21429836936423033, 0.21776747503570468, 0.20481225862041227, 0.20004562037411064, 0.2126093234917763, 0.18587251559429166, 0.1914795823633075, 0.2220915692589601, 0.22026154883403085, 0.2095169607948467, 0.24419130301495123, 0.20258106417241317, 0.19256047086342457, 0.21579044729382696, 0.1904761064184692, 0.2025487007988033, 0.2069205333891186, 0.19068752418294638, 0.21922896673775968, 0.1930899144070019, 0.19220310402439567, 0.20917812004223507, 0.2119003513712857, 0.2031579888026868, 0.20610075715949033, 0.20006816047409526, 0.20954588238859478, 0.22075539127766441, 0.20385507841150044, 0.2011923891562206, 0.2038580648392937, 0.20631211340103633]\n",
      "Male : [0.2152827131850462, 0.20966028180082275, 0.18616345957357253, 0.20520005166655017, 0.21797336468058165, 0.2230214937499057, 0.20561981114994168, 0.20507059934269065, 0.22051729204713205, 0.2685605229528114, 0.2143657399046168, 0.23398153147757497, 0.22032844470061475, 0.1915414343963161, 0.22533810750530944, 0.2047298028811669, 0.23046721513721882, 0.1925350373959182, 0.19999986768879688, 0.20211018572455433, 0.19200908095934918, 0.19687527175802033, 0.1855551707864636, 0.1999672442234883, 0.18019503269599665, 0.19695814364327607, 0.2081453901467376, 0.19817964548320813, 0.1967374414301946, 0.24457294616835779, 0.21021567649414838, 0.2127713656058436, 0.21058192826882627, 0.2231362121982676, 0.21056577777303637, 0.20627077557894224, 0.19473377330775246, 0.18962001698726078, 0.19022037771128736, 0.19791998617632311, 0.19595915179382728, 0.21825559807958544]\n",
      "Undefined Gender : [0.4354856741801695, 0.15926350664233815, 0.19821163687273044, 0.0, 0.1521182496374158, 0.22758391898928976, 0.13965027949045075, 0.05107268327763326, 0.07225557897087916, 0.05357901757805792, 0.2825717872629321, 0.15895698729092234, 0.37108153090783247, 0.15367047666270361, 0.2299274353036963, 0.1278036751789409, 0.08955230907194962, 0.15679569363109006, 0.0037548258201603097, 0.0757239762122895, 0.8590975759774409, 0.05810715565386574, 0.1379265607569368, 0.11514210606677093, 0.0, 0.03322776082949138, 0.087677796708495, 0.22493084013451364, 0.1183444048254188, 0.0, 0.0, 0.0, 0.0379953324630625, 0.0, 0.0, 0.0, 0.015614285897026719, 0.027838402970136136, 0.03772411752270612, 0.0, 0.0, 0.04248907530816806]\n",
      "+65 : [0.20388877926952906, 0.1941277470503436, 0.19459598497051286, 0.2172545076108372, 0.20955572426653207, 0.19046783182750826, 0.20253592221329783, 0.19564643733382728, 0.23923470919045445, 0.2026988156117537, 0.1919133490626357, 0.2091962571189479, 0.1933540209557641, 0.19609155902098316, 0.20995912049573653, 0.21419732245240813, 0.19084905541917863, 0.21098493191395204, 0.20004795889612378, 0.20022574485368919, 0.18829974414396577, 0.20766372536212455, 0.18541251657971128, 0.19596581358844217, 0.20289073982204936, 0.20565591558774443, 0.20701084225406807, 0.18785508587076155, 0.21229334878630332, 0.1917292871951901, 0.1939719307246425, 0.20434318720590627, 0.19760551910262278, 0.20655242874071694, 0.20618078882534713, 0.19473032033205334, 0.19300759301656076, 0.21933022508087072, 0.19925118311093615, 0.21694495657969473, 0.18359609730161616, 0.20058951181032578]\n",
      "-65 : [0.1996280272499198, 0.2170267565981958, 0.22213060122373687, 0.21769056366929435, 0.22604760223330073, 0.1910578816930861, 0.22630089716861343, 0.2188621270710108, 0.18703586083610282, 0.24608515223550972, 0.21366960735007912, 0.23041214924735384, 0.19387413672403378, 0.25406001281904417, 0.19081354067539288, 0.21737113503964353, 0.19059934142932103, 0.20162474089889015, 0.20445959008974465, 0.21269604080247762, 0.2034735815190236, 0.2001142588819813, 0.21265102454927337, 0.17735713656928034, 0.1985927405811477, 0.2446942181090724, 0.21183124616108204, 0.23496409018349113, 0.19301764896735982, 0.21310589572755467, 0.19933401290113362, 0.19624465790960768, 0.21390977139022282, 0.2308861524446744, 0.1943569876383454, 0.20800454227157983, 0.20680398133896785, 0.19809213450678212, 0.20780336307880157, 0.21458683175325374, 0.20708892745836624, 0.23363918932173033]\n",
      "ICUType 1 : [0.22260567999455774, 0.2157586138062674, 0.18825924671415367, 0.21138834683517257, 0.26026166672206846, 0.249548008829092, 0.1983496364567958, 0.19616255739157848, 0.16362756093630318, 0.2817687005250531, 0.18179618368480785, 0.20906001129684557, 0.17873493933674703, 0.21528069152239204, 0.25642147211956534, 0.21490243733285622, 0.2073158898945587, 0.19683751950561698, 0.19637622119359338, 0.23115018135041515, 0.17970799312727034, 0.24825584319038924, 0.22503544104278164, 0.19435039289907693, 0.19945288352178012, 0.20017548890408615, 0.25568756285130284, 0.2461814950560414, 0.23505626199607788, 0.18408394176615892, 0.23579552450280727, 0.21224824313567148, 0.18684197697366495, 0.21636806732659966, 0.2113247703884139, 0.23683260533340136, 0.2137802308166327, 0.18634004963109613, 0.1915372578853038, 0.20982494689821668, 0.18249277740929393, 0.2005632322867883]\n",
      "ICUType 2 : [0.1831842096601644, 0.20244318012934523, 0.16913904385493825, 0.21024361539544048, 0.16347136942612242, 0.18893432147730227, 0.18900683781218017, 0.18996348951093517, 0.17401764268268247, 0.1990411225565411, 0.1824170356239998, 0.19284049318229715, 0.2246756912876383, 0.1837096414505424, 0.19017601872117504, 0.17587705589672717, 0.16484126045325687, 0.1706856844412297, 0.21201074786386961, 0.16005761021215836, 0.18703751905248975, 0.1972382868400471, 0.1985894243615206, 0.1823606748980153, 0.20234222096199156, 0.18262596492329697, 0.1889145433218195, 0.1712994427532517, 0.17402022376675289, 0.18117334200004356, 0.1947679226529196, 0.18667838225455874, 0.18900154552465856, 0.16792373347887976, 0.1679935732670235, 0.16209652564322707, 0.20729134622171214, 0.17956144765659307, 0.18073357900093143, 0.1709630344096632, 0.19267229225131305, 0.17277557595820095]\n",
      "ICUType 3 : [0.266989898998708, 0.21040006642780598, 0.20836663776679615, 0.21999014645031972, 0.19705768945489271, 0.18449783824331897, 0.20339952601758016, 0.227475974835214, 0.19788705672872595, 0.3204314997368689, 0.22181025952363706, 0.25927785605104925, 0.19268459824224304, 0.2091683625319674, 0.21611242606348693, 0.2130930022080169, 0.22323201644769267, 0.20163972374253666, 0.22217111421888297, 0.2112754807624396, 0.19900486373856416, 0.20441986469616727, 0.22480520235233561, 0.20062479142222822, 0.187805684477957, 0.21910701569971167, 0.20894113691272737, 0.19156073603839774, 0.2462716486698127, 0.22478422564948156, 0.2004682467117365, 0.20639306314360825, 0.20333154424505925, 0.2053896269550334, 0.22447277588434755, 0.23857810333495566, 0.20017653304335067, 0.19602614875757585, 0.2214089184199658, 0.19496748306649647, 0.20935606516015154, 0.23131287630076794]\n",
      "ICUType 4 : [0.2253267703429504, 0.21714300440924264, 0.20958136882838627, 0.21086284628213045, 0.20186661632042974, 0.19730326171268434, 0.19886715962715115, 0.20839075051440378, 0.17571808251820467, 0.18180618389057884, 0.22069389216882632, 0.21963982588313388, 0.21567261559868328, 0.22108749538041797, 0.20881936195624826, 0.202670533309523, 0.21248088814665597, 0.2104129420965844, 0.22341886094386149, 0.19918991485873497, 0.23633180478808408, 0.22341038616109127, 0.19442054848044793, 0.20246836233888096, 0.22137093011415102, 0.21896720039148046, 0.1881303655528797, 0.20328046938375477, 0.18627290008744668, 0.20236074459822398, 0.21174088357956056, 0.1996466051424515, 0.2373781417605289, 0.23416914403984196, 0.21604280890110203, 0.2006979375069455, 0.19846969752890006, 0.2403291524068206, 0.19976281046136726, 0.22031280835550088, 0.20726635588885517, 0.20146992148218063]\n",
      "Undefined classification : [0.24062272882774857, 0.2209733916338602, 0.19360495692533122, 0.2649274536293681, 0.20246568447566493, 0.21842338078703452, 0.1934053992543839, 0.21185188878879185, 0.25906115480049996, 0.24133738631923066, 0.20957952256277512, 0.20501316185798696, 0.24307176919918547, 0.19981204524187487, 0.21772664212270634, 0.18969436014283655, 0.19646440792503017, 0.1912823123946036, 0.21052972473071951, 0.19892888392253355, 0.21074817173788735, 0.2001100939544115, 0.1814122421568192, 0.19336212952718373, 0.2009722829698927, 0.1988440735060306, 0.20469185696438433, 0.1885540235835251, 0.23281547862416116, 0.18025931258684483, 0.21153228211484748, 0.2061918769320727, 0.21845329008774636, 0.20182269571355382, 0.19250132772960313, 0.21492831092435444, 0.19980960289319516, 0.24112250028610152, 0.20622743146633205, 0.21661351656966013, 0.20812908653047685, 0.20879511168128403]\n",
      "Low Weight : [0.12066267954073209, 0.2575635383702113, 0.25281515186526915, 0.24165279030917755, 0.33006543999606636, 0.23608884593266016, 0.14920572225566578, 0.1581465929415339, 0.23335287149456715, 0.20687298148985298, 0.2536380430548473, 0.11630228588095667, 0.1610515428904473, 0.2179157163573344, 0.18273976705485284, 0.3118902463240719, 0.35465347313593953, 0.12418659356285193, 0.267703598954165, 0.3561810307238796, 0.1752195573803544, 0.18295325569605747, 0.21524269124252518, 0.1851091756221742, 0.31994702987917195, 0.4406930773183814, 0.21203711663032865, 0.36888041225449675, 0.2784504598383441, 0.24788903483049757, 0.26562625760431646, 0.2899720351111231, 0.1971585926947468, 0.17388602360498293, 0.21147974019824597, 0.242912730808787, 0.2124554454593815, 0.15375301567489852, 0.14651965994568808, 0.14491095065596576, 0.17338575758444177, 0.3495314265368016]\n",
      "Normal Weight : [0.22281435759400628, 0.20999557624024584, 0.20616384850170452, 0.22251581784527805, 0.1628265418533447, 0.20432581308889985, 0.23391446641815583, 0.15528757849275052, 0.19125778903335525, 0.16121631251798438, 0.23077667797649387, 0.19421590128536909, 0.21073094692932728, 0.19276278187574739, 0.1819462245441376, 0.17504134965999663, 0.2092393370472097, 0.15862574577120875, 0.1937232224595119, 0.18485986345533487, 0.16989308523664506, 0.22793608629687176, 0.21408623077226482, 0.22883070943594594, 0.16732760593332174, 0.19865729640466404, 0.2106314587734763, 0.18242847570631354, 0.1974020016894906, 0.20080494556403372, 0.18189725635327136, 0.17625021151206108, 0.21044712029503118, 0.1674987033559097, 0.21282485554542915, 0.17788845707775172, 0.21087253783482732, 0.1912217361854762, 0.19461750939925038, 0.18624847667909158, 0.189271820770922, 0.20530360802066122]\n",
      "Overweight : [0.20808900065408617, 0.17266490066318257, 0.19078941305453187, 0.2335509212291192, 0.17164672299814676, 0.22136239936204274, 0.22381861372986328, 0.2053453447066883, 0.23465482413448757, 0.16957860580061482, 0.24026838706850054, 0.19919154631058944, 0.26131276813952853, 0.1995316001588954, 0.20140752934477096, 0.22916986439984885, 0.20145446384074042, 0.19809925558135572, 0.20117970814559888, 0.2058373398307099, 0.1966369667845568, 0.17192270468483675, 0.20860790200810367, 0.18983648308456263, 0.18480688060796066, 0.19968702036878877, 0.20699203454763115, 0.17753732365988734, 0.2319410505752505, 0.18693610070890027, 0.22999489215226626, 0.2257369526924492, 0.16979700976717954, 0.1684494931539031, 0.17486427860099762, 0.17056536826185792, 0.17716385788491845, 0.30086184205143907, 0.1683540427420332, 0.20134835033190834, 0.1959782417960218, 0.2062077133072695]\n",
      "Obesity 1 : [0.15968112132797088, 0.23050869243996236, 0.18689351778316124, 0.2034308412825336, 0.19577297767320062, 0.19354353881857198, 0.19555600758713396, 0.17465646655028397, 0.1836488765282016, 0.17741550420321758, 0.24737953938869903, 0.243473748602128, 0.19861752180736444, 0.2361137162970999, 0.16028995666913579, 0.18266018301663803, 0.17055116120172265, 0.19462049309067536, 0.1907193112101876, 0.2074930235623298, 0.2254938685362774, 0.1398633504303176, 0.17955645320450395, 0.20311062870715924, 0.1796771820453987, 0.1765750752819916, 0.18525723238630284, 0.20485990019588715, 0.19465037957149012, 0.1533039872675148, 0.16903839134193502, 0.18484254189610835, 0.20981106725793378, 0.1853863356527884, 0.16560377469615511, 0.24308365369788473, 0.258520448056779, 0.22560427757402002, 0.20776781227085678, 0.22413209230831455, 0.2422519263112375, 0.2275685805857152]\n",
      "Obesity 2 : [0.18474538371248314, 0.20973692824764356, 0.24615448693036823, 0.2951894670561011, 0.16406689761614723, 0.14318998568221267, 0.17561104519459547, 0.16464380421184438, 0.19687976549135103, 0.15654498665439634, 0.1723079438396626, 0.16862596271152475, 0.2038015538160762, 0.2528543825957176, 0.20651551814726463, 0.22352382526250428, 0.16370934389493222, 0.22401265588993827, 0.18130479136593522, 0.19642024213226536, 0.20565297850834374, 0.2527868450490843, 0.3275654360248036, 0.16640512260325224, 0.23132314242745894, 0.246146647529811, 0.18533594831562764, 0.23989462982177012, 0.16663957939129226, 0.148815232918001, 0.2103728309994615, 0.18124186482054225, 0.16732991510689765, 0.19639844444998483, 0.2377198883250878, 0.15270987934096214, 0.16905170796609956, 0.1875089756777357, 0.17540795506387913, 0.1900223919655186, 0.20994184213499198, 0.2404486815079842]\n",
      "Obesity 3 : [0.19299390186234006, 0.16720466003955606, 0.22826805950764797, 0.24943358588378822, 0.25352357434175227, 0.18950493116152695, 0.16366323199736385, 0.18569459385435044, 0.19580129553185385, 0.1927439530020131, 0.21967062428892936, 0.22870952369526104, 0.26059298046169427, 0.33340884184766406, 0.2566381237185397, 0.21236673060478217, 0.20260249015738038, 0.2737004979496182, 0.17739335791549632, 0.1991102060583555, 0.22706455754555385, 0.2655068744658235, 0.2781218299986502, 0.15946320531901154, 0.15646007526855432, 0.27140885804434595, 0.13923133573543867, 0.24756599953633346, 0.18882092506013268, 0.17756245197057388, 0.24631829780954612, 0.21816594865091943, 0.21168985314978736, 0.17192062296423583, 0.20562045008872043, 0.16021869771306335, 0.171260382006984, 0.216291636995846, 0.14966518841318244, 0.2271753694819843, 0.211519057252226, 0.17992184156861038]\n"
     ]
    }
   ],
   "source": [
    "print(\"SAITS - MAE\")\n",
    "print(\"-------------\")\n",
    "for i in range(len(subgroups)):\n",
    "    print(subgroups[i], \":\" ,testing_mae_saits_append_subgroups[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRITS - MAE\n",
      "-------------\n",
      "General : [0.1962358019693381, 0.20542357592674076, 0.1979216866218381, 0.21234099306466156, 0.19585661894886525, 0.2080356559322864, 0.21492250081022543, 0.2187574466914169, 0.22451208701626463, 0.20534600951292856, 0.20161345757400367, 0.21571329323125008, 0.22548847222615792, 0.19562882462622477, 0.1906580070514125, 0.192236055292469, 0.2027099126832753, 0.20289585947022934, 0.2021046325940434, 0.20268077647893198, 0.19416009340782187, 0.21771963348665715, 0.19259169838636778, 0.19840813990637, 0.19654472241928775, 0.20458692540807955, 0.208304236080579, 0.198183506126367, 0.20439084666758744, 0.19867903061675873, 0.21813141793117619, 0.20837618191478277, 0.20929837620746616, 0.19711017965951236, 0.19789701798789477, 0.2074465156434963, 0.20109083397960958, 0.21883669923438365, 0.20014034149217563, 0.21575077429591716, 0.20188151679612304, 0.21318694504483018]\n",
      "Female : [0.18623341232781088, 0.19501365077846933, 0.19024424406610316, 0.24286887087861292, 0.2011510552054136, 0.19107874561820012, 0.20119199864491139, 0.18491243975109764, 0.23675676601595133, 0.18156606499389552, 0.22245141041103705, 0.21833464016419055, 0.2155771490726591, 0.18860537994027696, 0.21240363969443424, 0.19010250378997742, 0.1743242506233624, 0.2195306570934887, 0.2236905115294531, 0.21441637688302634, 0.24580115087565235, 0.20228586673929846, 0.1942017684143302, 0.20409019602651504, 0.19377947650754979, 0.2114214153518484, 0.2002270800463301, 0.19141152106681666, 0.22794498539922015, 0.19581534113181903, 0.1908800626267683, 0.21210933336533208, 0.21167475252325935, 0.2066389464131578, 0.2072743806810387, 0.1957990214362309, 0.19848684410179868, 0.22480739500106173, 0.19987399724019406, 0.1935185100750599, 0.20370363678357084, 0.20560697477913037]\n",
      "Male : [0.21199086717531263, 0.2160599960073371, 0.18283495286244045, 0.22600964190285322, 0.21357554849469235, 0.240237985096413, 0.20323964426784166, 0.20100658633096558, 0.2170786275217326, 0.2643705836163725, 0.22322417353573104, 0.32918737977113094, 0.22730907234276643, 0.1857205193153478, 0.2164204157884438, 0.20012630997975955, 0.2251081057412039, 0.1960115804393042, 0.2089524332473231, 0.20325447944619252, 0.20973179176996581, 0.18481242357066832, 0.1927484263235477, 0.19490760740787177, 0.17323334935599424, 0.2017110229595331, 0.2029172061121037, 0.18958236135196724, 0.20741572561946206, 0.25146208337110215, 0.22017323960132099, 0.21839367707638305, 0.20545316011499298, 0.22148437751848085, 0.2210857720330747, 0.19556618001744414, 0.20117660166606266, 0.18776526124174878, 0.17899950067041917, 0.2102964955321978, 0.20408502209629822, 0.21987015097358142]\n",
      "Undefined Gender : [0.40893191344950985, 0.1920888313267032, 0.18962958826228993, 0.0, 0.19466471694227663, 0.13366966348947346, 0.12218315324018955, 0.08511424464635765, 0.14018257292253775, 0.01563263565079221, 0.3035451652392034, 0.15487335479138847, 0.3591002579406241, 0.07394530752313312, 0.19175084996362673, 0.16116942316398344, 0.02747888153484404, 0.1472947740556735, 0.030931444396182936, 0.10628741452349853, 0.4121885013060233, 0.08180029997529555, 0.017134436714942552, 0.4897660771499752, 0.0, 0.013821442164960007, 0.0833393608798114, 0.24982296913850904, 0.06711938334395605, 0.0, 0.0, 0.0, 0.0019260585144291354, 0.0, 0.0, 0.0, 0.02287028713107403, 0.005021161783835424, 0.05987866711083274, 0.0, 0.0, 0.0064424511245493275]\n",
      "+65 : [0.20433781542053672, 0.20242867534926756, 0.18682700693978574, 0.21861752981769958, 0.21218090686548918, 0.1813804109770614, 0.203098088588961, 0.19163386480445724, 0.24539883136432317, 0.18095025938277118, 0.17896075282097212, 0.31599459213454706, 0.20188854938654688, 0.19876739141954078, 0.20576632402997647, 0.215749330947668, 0.184754137931833, 0.21458028984210725, 0.20175667959451665, 0.20363132938207046, 0.19276221177416278, 0.20517557868472588, 0.1848734468633399, 0.1931672331383526, 0.20840073684732147, 0.20790285403284767, 0.21997706651064083, 0.19449879569126494, 0.21459408132889612, 0.18830812701675187, 0.1903902447038713, 0.20107801921094562, 0.194799793888259, 0.21008429646652235, 0.2041081320463714, 0.18893983432551822, 0.19073371523664387, 0.2266505700414736, 0.19885152981873833, 0.2264403020939058, 0.1800204538278262, 0.19061501374510104]\n",
      "-65 : [0.20615306535809305, 0.20880134207206993, 0.22689071121204096, 0.22586825920865736, 0.22799702149296777, 0.1968448220516807, 0.2282025832160359, 0.21642700884424226, 0.1863180805111229, 0.2415049715888738, 0.2200533880890337, 0.22908272613605946, 0.18920997652409852, 0.24992709406058206, 0.19455505400845874, 0.20781281533691037, 0.2000171122338892, 0.1955668427423355, 0.210123928246789, 0.21736229008923022, 0.2146505130117695, 0.1934165428582511, 0.21940721285629392, 0.18158543278119368, 0.20190430897346495, 0.2533869000153999, 0.20747119591963886, 0.2313280409757424, 0.1885128826649794, 0.22633880444301174, 0.19819228205951778, 0.21407827992339953, 0.21414755776869834, 0.24606237926355765, 0.19336966626650665, 0.22405011351424828, 0.2124558930912826, 0.19862272079348642, 0.22444676436620867, 0.22766242375145, 0.21319666781916854, 0.24591056589436863]\n",
      "ICUType 1 : [0.25957615581103033, 0.21081398045226796, 0.19155420227585085, 0.20934296258008078, 0.26192857910891915, 0.27746338788672753, 0.18665622607771515, 0.1890725915565898, 0.15988404716438467, 0.29150730366378985, 0.2016651697932546, 0.19449047758608312, 0.1975773998618663, 0.21258515449688206, 0.27941517381154796, 0.21268951418685542, 0.19673190126439677, 0.2014618633678009, 0.21556876981098289, 0.21970295762445352, 0.18242789718796196, 0.25572266171628794, 0.2494971295663659, 0.18376300943234805, 0.2015069086721127, 0.21470975333866943, 0.24362002895030424, 0.23113419363663537, 0.2494750956928469, 0.21388264041398025, 0.2323242530774774, 0.24055277140945228, 0.18250348206472192, 0.23622565175097354, 0.21697902561460905, 0.23593063808851053, 0.22545050106167538, 0.18102262981409967, 0.17782121219380967, 0.2114024797168081, 0.1852227924648066, 0.21844993432302767]\n",
      "ICUType 2 : [0.1799268781115655, 0.20036617744625768, 0.17447908186170094, 0.2062820155663514, 0.16198811274748937, 0.19390754585083905, 0.174918629083463, 0.17414905573755587, 0.15447258625128993, 0.19902251996825482, 0.17524557833222817, 0.19282003687856605, 0.4623376486947577, 0.20195535526683323, 0.1717579335750688, 0.1622054136207419, 0.15682387203597906, 0.16966915045752237, 0.2060846927661583, 0.15443159430578457, 0.18541386796523832, 0.18420872352889398, 0.19103919975658246, 0.17522983364301414, 0.1990492994656287, 0.18101397505859818, 0.18282125274171, 0.16110475473816177, 0.15454152513456929, 0.17870652723089067, 0.19146741796021852, 0.17126918716240017, 0.17778541116379726, 0.15999379150992463, 0.15906440773531205, 0.1656806093952352, 0.21880855924155876, 0.19850682218791338, 0.18466358296902158, 0.15376154692372834, 0.17004106718710088, 0.1706070500977225]\n",
      "ICUType 3 : [0.27661400952305015, 0.2249828276038612, 0.2193934797395457, 0.23318864812828594, 0.2083938495046533, 0.19976186334812607, 0.2118488552133255, 0.2341377831214832, 0.20147620332534738, 0.2966933365326733, 0.23670715397712744, 0.27129417090432156, 0.22433073211356633, 0.21138790895786613, 0.21469151457800356, 0.22130922281081908, 0.23706378145107235, 0.20267124184740887, 0.23739806928954196, 0.20790858720913125, 0.2110615876200566, 0.2103839843907337, 0.24920711730809697, 0.21900265765286256, 0.19830935168818967, 0.23091198325632384, 0.2001916853781682, 0.18893147433946036, 0.2526345724685273, 0.2245388196693829, 0.21555673035745992, 0.21344904882666058, 0.2200407749260856, 0.20800809797470385, 0.2260167350909894, 0.23787211893539933, 0.2118453597424291, 0.20023602246198086, 0.2186726074089189, 0.21368643223725126, 0.21129373312029304, 0.22151447122049125]\n",
      "ICUType 4 : [0.23227007967994281, 0.2205954639998652, 0.20743337398498057, 0.1956070700196481, 0.19332317150075867, 0.20555296379902838, 0.20519673300352395, 0.21408302503362048, 0.1859960343170504, 0.1779441225960908, 0.22739679239820548, 0.2380688945979194, 0.211513568108809, 0.22409092349170748, 0.21252079638757954, 0.19556922772628965, 0.19618531039034262, 0.20141293979087171, 0.24237359966283245, 0.20119517296414413, 0.2293299475277016, 0.21513386401732734, 0.1923649308520289, 0.19438669025630695, 0.21346645879183773, 0.2145054283185121, 0.17975618260857204, 0.20844561214305418, 0.18870407816922505, 0.19054900102688102, 0.2237223011987439, 0.20560508869967864, 0.22801589165512878, 0.23974000124739506, 0.21988705609581083, 0.19883948951724867, 0.20494596007202395, 0.24081282950899988, 0.20513361507116523, 0.2064408093473171, 0.19589545578664017, 0.1925041898830655]\n",
      "Undefined classification : [0.26562146075652227, 0.22612038317545471, 0.2038787564986835, 0.2721902431708097, 0.21267936498293064, 0.23074797809532344, 0.20557581342838974, 0.2146908474014933, 0.2552092008383474, 0.24012728547907558, 0.20836598437869128, 0.2144132322869564, 0.2590894405136772, 0.20754412920469437, 0.22252488582585792, 0.19346492768515133, 0.20685401450664156, 0.19615120097764105, 0.2001928679450444, 0.19067513082151333, 0.22724522379814147, 0.20905162492023902, 0.19037979532774196, 0.1833659809600484, 0.20590727412551318, 0.20339925364311237, 0.2013091846107651, 0.18930769914498177, 0.23177563592477918, 0.18401784534565593, 0.22040329145137397, 0.21539472115173652, 0.21604035480563838, 0.20187030998061212, 0.20573002534851123, 0.22002360315829933, 0.21056329979326985, 0.23863891261290254, 0.2126384138466004, 0.23729498267049082, 0.2215369132077554, 0.20914430813134482]\n",
      "Low Weight : [0.13129621323200277, 0.2641900387297639, 0.31532563883578235, 0.19126604329291874, 0.3406622791989629, 0.2339011627669594, 0.17234405407136763, 0.14606417085304393, 0.22647783100703517, 0.20065156616164262, 0.2466120256029715, 0.09173940198185898, 0.15140638965551503, 0.23085506812991638, 0.13602607733414648, 0.2568931091797553, 0.30129419312365446, 0.14672608489418404, 0.31583279634129185, 0.35649960334180814, 0.20960478683578807, 0.24655012379979452, 0.1793657373042344, 0.17912254758333176, 0.4125180126427117, 0.5060386973169435, 0.20038853415021898, 0.3344915979772853, 0.31847037271655443, 0.24743434800357295, 0.20407873072461274, 0.30946225671919575, 0.24560900926670207, 0.24642940272878205, 0.20401454517456882, 0.226846443334149, 0.2187103736231176, 0.12397228557532, 0.15257960367961948, 0.11354216125721966, 0.187498066906193, 0.3995682481163394]\n",
      "Normal Weight : [0.2330356341120651, 0.19364756414357506, 0.19021945824240094, 0.2261388774690923, 0.1579652242767881, 0.19805575473641432, 0.2333247583146486, 0.16322617047920573, 0.1801824603018148, 0.17018936138919324, 0.2192568708796325, 0.20157137508462764, 0.5972011382683983, 0.17527183291556356, 0.18767294570165638, 0.1749945301434378, 0.21618850495943856, 0.1462311349346293, 0.18398275169840678, 0.1684115898068566, 0.18189812521702656, 0.22622727037340545, 0.2169997922171081, 0.2247930971684758, 0.1671652040179431, 0.209198813872819, 0.1964467850162253, 0.17064565293807565, 0.18051906051577254, 0.20143299336676376, 0.17403281626797817, 0.17497485837823887, 0.20091346398732007, 0.15169109174922266, 0.2373053735860858, 0.1727745544033589, 0.18796362403898784, 0.2001162002772804, 0.1965965660544487, 0.1968879638722994, 0.18636877129679483, 0.18555226736530184]\n",
      "Overweight : [0.2042561723330766, 0.1760453947685374, 0.20112868048705113, 0.21834354080715576, 0.16525131007916358, 0.22027271394217454, 0.21140771924372895, 0.21165518881126558, 0.21646854671297208, 0.16544217989664525, 0.2280360690772709, 0.2108752338232841, 0.247881188387378, 0.20669117345869958, 0.19663391879664324, 0.2186059421323494, 0.1900846616722372, 0.17517955689793355, 0.1814062902701398, 0.19890836907002293, 0.18574401596341897, 0.1665514356568572, 0.20378154836518556, 0.19972152787932382, 0.16626679202193248, 0.17850440444068, 0.20553764249512327, 0.17255668015070985, 0.22749192794164774, 0.18830733821378212, 0.2472020892738092, 0.22468848815745407, 0.16950995669113847, 0.16633265949437773, 0.1662149586551081, 0.15701675465125245, 0.16518673749859597, 0.2918041688275442, 0.15960778766374903, 0.19043215996246204, 0.19945863101808672, 0.21145894787311592]\n",
      "Obesity 1 : [0.1392668568228805, 0.2498210105687836, 0.17864818424996956, 0.2054472383748177, 0.1965209177418826, 0.16876878900803288, 0.1929842321784305, 0.18671693659491514, 0.19054750658084021, 0.18759475826982552, 0.23403356516135124, 0.23111574779960395, 0.17765298322597733, 0.20892027478343297, 0.1552383562514035, 0.1576800427251824, 0.17520712217801562, 0.1967840105392502, 0.16357643334716332, 0.20443631539745918, 0.20821644817434712, 0.13228795513565172, 0.14606939604187658, 0.1831154152807438, 0.18266053276569327, 0.17424586917684154, 0.14990510110064958, 0.22840297120145212, 0.1986209660783441, 0.14130415506007463, 0.21769455143720437, 0.16595696038636334, 0.20157597910142644, 0.17086048840941304, 0.17193417513166098, 0.24242125326078462, 0.21919328742624392, 0.22189725931102924, 0.17746132347452534, 0.180522206215815, 0.21508237617260337, 0.23177549703689218]\n",
      "Obesity 2 : [0.17660942620879144, 0.19401632300443306, 0.2971453401056689, 0.3437112568185359, 0.15020405824405475, 0.14591792690684327, 0.1649555795844898, 0.1707802692644589, 0.19114889463546028, 0.11879255952849747, 0.17099557521898587, 0.18405874893065985, 0.19122018826795192, 0.2737835064525044, 0.22174131916940587, 0.24088282927013402, 0.16935210461630248, 0.23852404966238866, 0.19603035037686767, 0.17990197509196074, 0.17780783914417556, 0.2652230732814027, 0.3313254829765281, 0.1364813168400165, 0.22565447622226784, 0.2607394512463326, 0.22672988266552085, 0.22886944230564532, 0.15135450456424585, 0.14614643073404585, 0.18924124262691872, 0.1971185637439094, 0.17003328682426758, 0.196372640595159, 0.23609402265486543, 0.1543798659552121, 0.17933289065699554, 0.20089174844438595, 0.15805781904532953, 0.15823373967187404, 0.21987574225259943, 0.17284141463086317]\n",
      "Obesity 3 : [0.19973120616682283, 0.1536795849756947, 0.19726163573833325, 0.27159676662636223, 0.2779835134567844, 0.1804225415302549, 0.16125131191278527, 0.17234676053308715, 0.24003632131647631, 0.15851395833998866, 0.22297705322502054, 0.20508481420691108, 0.262439525915989, 0.3619935705650686, 0.2280694427719875, 0.19781759321707315, 0.20140044603198523, 0.2659201075045272, 0.12601356970639196, 0.20075495300131874, 0.19915609543878418, 0.25970425165675554, 0.26908767552889334, 0.14934041909264947, 0.11992618017602676, 0.2259345954782973, 0.13610291751714484, 0.2906995126810794, 0.1674309656084601, 0.16911633380212313, 0.26792154971082055, 0.30966407923353473, 0.2016536047113171, 0.167462616549042, 0.2040824131732267, 0.17292414742814258, 0.1859306058846489, 0.37835385724239656, 0.13644362616571581, 0.2544664920803028, 0.22930760746560072, 0.21378633141231607]\n"
     ]
    }
   ],
   "source": [
    "print(\"BRITS - MAE\")\n",
    "print(\"-------------\")\n",
    "for i in range(len(subgroups)):\n",
    "    print(subgroups[i], \":\" ,testing_mae_brits_append_subgroups[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
