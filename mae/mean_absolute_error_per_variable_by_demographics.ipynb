{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 23:01:18.247549: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742263278.262716  171926 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742263278.267601  171926 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-17 23:01:18.283283: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/local/lib/python3.11/dist-packages/pypots/nn/functional/cuda.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  return autocast(**kwargs)\n",
      "/usr/local/lib/python3.11/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-03-17 23:01:20 [WARNING]: ‼️ `pypots.utils.metrics` is deprecated. Please import from `pypots.nn.functional` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "████████╗██╗███╗   ███╗███████╗    ███████╗███████╗██████╗ ██╗███████╗███████╗    █████╗ ██╗\n",
      "╚══██╔══╝██║████╗ ████║██╔════╝    ██╔════╝██╔════╝██╔══██╗██║██╔════╝██╔════╝   ██╔══██╗██║\n",
      "   ██║   ██║██╔████╔██║█████╗█████╗███████╗█████╗  ██████╔╝██║█████╗  ███████╗   ███████║██║\n",
      "   ██║   ██║██║╚██╔╝██║██╔══╝╚════╝╚════██║██╔══╝  ██╔══██╗██║██╔══╝  ╚════██║   ██╔══██║██║\n",
      "   ██║   ██║██║ ╚═╝ ██║███████╗    ███████║███████╗██║  ██║██║███████╗███████║██╗██║  ██║██║\n",
      "   ╚═╝   ╚═╝╚═╝     ╚═╝╚══════╝    ╚══════╝╚══════╝╚═╝  ╚═╝╚═╝╚══════╝╚══════╝╚═╝╚═╝  ╚═╝╚═╝\n",
      "ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai \u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pypots\n",
    "import os\n",
    "import sys\n",
    "from pypots.utils.metrics import calc_mae\n",
    "from pypots.optim import Adam\n",
    "from pypots.imputation import SAITS, BRITS, MRNN, USGAN, GPVAE\n",
    "import numpy as np\n",
    "import benchpots\n",
    "from pypots.utils.random import set_random_seed\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 23:01:23 [INFO]: Have set the random seed as 2022 for numpy and pytorch.\n",
      "2025-03-17 23:01:23 [INFO]: You're using dataset physionet_2012, please cite it properly in your work. You can find its reference information at the below link: \n",
      "https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/physionet_2012\n",
      "2025-03-17 23:01:23 [INFO]: Dataset physionet_2012 has already been downloaded. Processing directly...\n",
      "2025-03-17 23:01:23 [INFO]: Dataset physionet_2012 has already been cached. Loading from cache directly...\n",
      "2025-03-17 23:01:23 [INFO]: Loaded successfully!\n",
      "2025-03-17 23:01:37 [WARNING]: Note that physionet_2012 has sparse observations in the time series, hence we don't add additional missing values to the training dataset. \n",
      "2025-03-17 23:01:37 [WARNING]: Note that physionet_2012 has sparse observations in the time series, hence we don't add additional missing values to the training dataset. \n",
      "2025-03-17 23:01:37 [INFO]: 68807 values masked out in the val set as ground truth, take 9.97% of the original observed values\n",
      "2025-03-17 23:01:37 [INFO]: 68807 values masked out in the val set as ground truth, take 9.97% of the original observed values\n",
      "2025-03-17 23:01:37 [INFO]: 86319 values masked out in the test set as ground truth, take 9.99% of the original observed values\n",
      "2025-03-17 23:01:37 [INFO]: 86319 values masked out in the test set as ground truth, take 9.99% of the original observed values\n",
      "2025-03-17 23:01:37 [INFO]: Total sample number: 11988\n",
      "2025-03-17 23:01:37 [INFO]: Total sample number: 11988\n",
      "2025-03-17 23:01:37 [INFO]: Training set size: 7671 (63.99%)\n",
      "2025-03-17 23:01:37 [INFO]: Training set size: 7671 (63.99%)\n",
      "2025-03-17 23:01:37 [INFO]: Validation set size: 1918 (16.00%)\n",
      "2025-03-17 23:01:37 [INFO]: Validation set size: 1918 (16.00%)\n",
      "2025-03-17 23:01:37 [INFO]: Test set size: 2399 (20.01%)\n",
      "2025-03-17 23:01:37 [INFO]: Test set size: 2399 (20.01%)\n",
      "2025-03-17 23:01:37 [INFO]: Number of steps: 48\n",
      "2025-03-17 23:01:37 [INFO]: Number of steps: 48\n",
      "2025-03-17 23:01:37 [INFO]: Number of features: 37\n",
      "2025-03-17 23:01:37 [INFO]: Number of features: 37\n",
      "2025-03-17 23:01:37 [INFO]: Train set missing rate: 79.70%\n",
      "2025-03-17 23:01:37 [INFO]: Train set missing rate: 79.70%\n",
      "2025-03-17 23:01:37 [INFO]: Validating set missing rate: 81.75%\n",
      "2025-03-17 23:01:37 [INFO]: Validating set missing rate: 81.75%\n",
      "2025-03-17 23:01:37 [INFO]: Test set missing rate: 81.75%\n",
      "2025-03-17 23:01:37 [INFO]: Test set missing rate: 81.75%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['n_classes', 'n_steps', 'n_features', 'scaler', 'train_X', 'train_y', 'train_ICUType', 'val_X', 'val_y', 'val_ICUType', 'test_X', 'test_y', 'test_ICUType', 'female_gender_test_X', 'female_gender_test_y', 'test_ICUType_female_gender', 'male_gender_test_X', 'male_gender_test_y', 'test_ICUType_male_gender', 'undefined_gender_test_X', 'undefined_gender_test_y', 'test_ICUType_undefined_gender', 'more_than_or_equal_to_65_test_X', 'more_than_or_equal_to_65_test_y', 'test_ICUType_more_than_or_equal_to_65', 'less_than_65_test_X', 'less_than_65_test_y', 'test_ICUType_less_than_65', 'ICUType_1_test_X', 'ICUType_1_test_y', 'test_ICUType_1', 'ICUType_2_test_X', 'ICUType_2_test_y', 'test_ICUType_2', 'ICUType_3_test_X', 'ICUType_3_test_y', 'test_ICUType_3', 'ICUType_4_test_X', 'ICUType_4_test_y', 'test_ICUType_4', 'classificacao_undefined_test_X', 'classificacao_undefined_test_y', 'test_ICUType_classificacao_undefined', 'classificacao_baixo_peso_test_X', 'classificacao_baixo_peso_test_y', 'test_ICUType_classificao_baixo_peso', 'classificacao_normal_peso_test_X', 'classificacao_normal_peso_test_y', 'test_ICUType_classificacao_normal_peso', 'classificacao_sobrepeso_test_X', 'classificacao_sobrepeso_test_y', 'test_ICUType_classificacao_sobrepeso', 'classificacao_obesidade_1_test_X', 'classificacao_obesidade_1_test_y', 'test_ICUType_classificacao_obesidade_1', 'classificacao_obesidade_2_test_X', 'classificacao_obesidade_2_test_y', 'test_ICUType_classificacao_obesidade_2', 'classificacao_obesidade_3_test_X', 'classificacao_obesidade_3_test_y', 'test_ICUType_classificacao_obesidade_3', 'val_X_ori', 'test_X_ori', 'female_gender_test_X_ori', 'male_gender_test_X_ori', 'undefined_gender_test_X_ori', 'more_than_or_equal_to_65_test_X_ori', 'less_than_65_test_X_ori', 'ICUType_1_test_X_ori', 'ICUType_2_test_X_ori', 'ICUType_3_test_X_ori', 'ICUType_4_test_X_ori', 'classificacao_undefined_test_X_ori', 'classificacao_baixo_peso_test_X_ori', 'classificacao_normal_peso_test_X_ori', 'classificacao_sobrepeso_test_X_ori', 'classificacao_obesidade_1_test_X_ori', 'classificacao_obesidade_2_test_X_ori', 'classificacao_obesidade_3_test_X_ori'])\n"
     ]
    }
   ],
   "source": [
    "set_random_seed()\n",
    "\n",
    "from pypotsModify.benchpotsMAE.datasets import preprocess_physionet2012\n",
    "\n",
    "# Load the PhysioNet-2012 dataset\n",
    "physionet2012_dataset = preprocess_physionet2012(subset=\"all\", rate=0.1, normalization = 1)\n",
    "\n",
    "# Take a look at the generated PhysioNet-2012 dataset, you'll find that everything has been prepared for you,\n",
    "# data splitting, normalization, additional artificially-missing values for evaluation, etc.\n",
    "print(physionet2012_dataset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assemble the datasets for training\n",
    "dataset_for_training = {\n",
    "    \"X\": physionet2012_dataset['train_X'],\n",
    "}\n",
    "# assemble the datasets for validation\n",
    "dataset_for_validating = {\n",
    "    \"X\": physionet2012_dataset['val_X'],\n",
    "    \"X_ori\": physionet2012_dataset['val_X_ori'],\n",
    "}\n",
    "\n",
    "dataset_for_testing_ori = {\n",
    "    \"X_ori\": physionet2012_dataset['test_X_ori'],\n",
    "    \"female_gender_test_X_ori\": physionet2012_dataset['female_gender_test_X_ori'],\n",
    "    \"male_gender_test_X_ori\": physionet2012_dataset['male_gender_test_X_ori'],\n",
    "    \"undefined_gender_test_X_ori\": physionet2012_dataset['undefined_gender_test_X_ori'],\n",
    "    \"more_than_or_equal_to_65_test_X_ori\":  physionet2012_dataset['more_than_or_equal_to_65_test_X_ori'],\n",
    "    \"less_than_65_test_X_ori\": physionet2012_dataset['less_than_65_test_X_ori'],\n",
    "    \"ICUType_1_test_X_ori\": physionet2012_dataset['ICUType_1_test_X_ori'],\n",
    "    \"ICUType_2_test_X_ori\": physionet2012_dataset['ICUType_2_test_X_ori'],\n",
    "    \"ICUType_3_test_X_ori\": physionet2012_dataset['ICUType_3_test_X_ori'],\n",
    "    \"ICUType_4_test_X_ori\": physionet2012_dataset['ICUType_4_test_X_ori'],\n",
    "    \"classificacao_undefined_test_X_ori\": physionet2012_dataset['classificacao_undefined_test_X_ori'],\n",
    "    \"classificacao_baixo_peso_test_X_ori\": physionet2012_dataset['classificacao_baixo_peso_test_X_ori'],\n",
    "    \"classificacao_normal_peso_test_X_ori\": physionet2012_dataset['classificacao_normal_peso_test_X_ori'],\n",
    "    \"classificacao_sobrepeso_test_X_ori\": physionet2012_dataset['classificacao_sobrepeso_test_X_ori'],\n",
    "    \"classificacao_obesidade_1_test_X_ori\": physionet2012_dataset['classificacao_obesidade_1_test_X_ori'],\n",
    "    \"classificacao_obesidade_2_test_X_ori\": physionet2012_dataset['classificacao_obesidade_2_test_X_ori'],\n",
    "    \"classificacao_obesidade_3_test_X_ori\": physionet2012_dataset['classificacao_obesidade_3_test_X_ori']\n",
    "}\n",
    "\n",
    "# assemble the datasets for test\n",
    "dataset_for_testing = {\n",
    "    \"X\": physionet2012_dataset['test_X'],\n",
    "    \"female_gender_test_X\": physionet2012_dataset['female_gender_test_X'],\n",
    "    \"male_gender_test_X\": physionet2012_dataset['male_gender_test_X'],\n",
    "    \"undefined_gender_test_X\": physionet2012_dataset['undefined_gender_test_X'],\n",
    "    \"more_than_or_equal_to_65_test_X\":  physionet2012_dataset['more_than_or_equal_to_65_test_X'],\n",
    "    \"less_than_65_test_X\": physionet2012_dataset['less_than_65_test_X'],\n",
    "    \"ICUType_1_test_X\": physionet2012_dataset['ICUType_1_test_X'],\n",
    "    \"ICUType_2_test_X\": physionet2012_dataset['ICUType_2_test_X'],\n",
    "    \"ICUType_3_test_X\": physionet2012_dataset['ICUType_3_test_X'],\n",
    "    \"ICUType_4_test_X\": physionet2012_dataset['ICUType_4_test_X'],\n",
    "    \"classificacao_undefined_test_X\": physionet2012_dataset['classificacao_undefined_test_X'],\n",
    "    \"classificacao_baixo_peso_test_X\": physionet2012_dataset['classificacao_baixo_peso_test_X'],\n",
    "    \"classificacao_normal_peso_test_X\": physionet2012_dataset['classificacao_normal_peso_test_X'],\n",
    "    \"classificacao_sobrepeso_test_X\": physionet2012_dataset['classificacao_sobrepeso_test_X'],\n",
    "    \"classificacao_obesidade_1_test_X\": physionet2012_dataset['classificacao_obesidade_1_test_X'],\n",
    "    \"classificacao_obesidade_2_test_X\": physionet2012_dataset['classificacao_obesidade_2_test_X'],\n",
    "    \"classificacao_obesidade_3_test_X\": physionet2012_dataset['classificacao_obesidade_3_test_X']\n",
    "}\n",
    "## calculate the mask to indicate the ground truth positions in test_X_ori, will be used by metric funcs to evaluate models\n",
    "test_X_indicating_mask = []\n",
    "test_X_ori = []\n",
    "for i, j in zip(dataset_for_testing_ori.values(), dataset_for_testing.values()):\n",
    "    test_X_indicating_mask.append(np.isnan(i) ^ np.isnan(j))\n",
    "    test_X_ori.append(np.nan_to_num(i))   # metric functions do not accpet input with NaNs, hence fill NaNs with 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicialize the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Inicialize new model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 23:03:27 [INFO]: No given device, using default device: cpu\n",
      "2025-03-17 23:03:27 [INFO]: Model files will be saved to tutorial_results/imputation/saits/20250317_T230327\n",
      "2025-03-17 23:03:27 [INFO]: Tensorboard file will be saved to tutorial_results/imputation/saits/20250317_T230327/tensorboard\n",
      "2025-03-17 23:03:27 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 720,182\n"
     ]
    }
   ],
   "source": [
    "saits = SAITS(\n",
    "    n_steps=physionet2012_dataset['n_steps'],\n",
    "    n_features=physionet2012_dataset['n_features'],\n",
    "    n_layers=1,\n",
    "    d_model=256,\n",
    "    d_ffn=128,\n",
    "    n_heads=4,\n",
    "    d_k=64,\n",
    "    d_v=64,\n",
    "    dropout=0.1,\n",
    "    ORT_weight=1,  # you can adjust the weight values of arguments ORT_weight\n",
    "    # and MIT_weight to make the SAITS model focus more on one task. Usually you can just leave them to the default values, i.e. 1.\n",
    "    MIT_weight=1,\n",
    "    batch_size=32,\n",
    "    # here we set epochs=10 for a quick demo, you can set it to 100 or more for better performance\n",
    "    epochs=10,\n",
    "    # here we set patience=3 to early stop the training if the evaluting loss doesn't decrease for 3 epoches.\n",
    "    # You can leave it to defualt as None to disable early stopping.\n",
    "    patience=3,\n",
    "    # give the optimizer. Different from torch.optim.Optimizer, you don't have to specify model's parameters when\n",
    "    # initializing pypots.optim.Optimizer. You can also leave it to default. It will initilize an Adam optimizer with lr=0.001.\n",
    "    optimizer=Adam(lr=1e-3),\n",
    "    # this num_workers argument is for torch.utils.data.Dataloader. It's the number of subprocesses to use for data loading.\n",
    "    # Leaving it to default as 0 means data loading will be in the main process, i.e. there won't be subprocesses.\n",
    "    # You can increase it to >1 if you think your dataloading is a bottleneck to your model training speed\n",
    "    num_workers=0,\n",
    "    # just leave it to default as None, PyPOTS will automatically assign the best device for you.\n",
    "    # Set it as 'cpu' if you don't have CUDA devices. You can also set it to 'cuda:0' or 'cuda:1' if you have multiple CUDA devices, even parallelly on ['cuda:0', 'cuda:1']\n",
    "    device=None,\n",
    "    # set the path for saving tensorboard and trained model files\n",
    "    saving_path=\"tutorial_results/imputation/saits\",\n",
    "    # only save the best model after training finished.\n",
    "    # You can also set it as \"better\" to save models performing better ever during training.\n",
    "    model_saving_strategy=\"best\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Inicialize existing model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 19:17:38 [INFO]: No given device, using default device: cpu\n",
      "2025-03-16 19:17:38 [WARNING]: ‼️ saving_path not given. Model files and tensorboard file will not be saved.\n",
      "2025-03-16 19:17:38 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 720,182\n"
     ]
    }
   ],
   "source": [
    "saits = SAITS(\n",
    "    n_steps=physionet2012_dataset['n_steps'],\n",
    "    n_features=physionet2012_dataset['n_features'],\n",
    "    n_layers=1,\n",
    "    d_model=256,\n",
    "    d_ffn=128,\n",
    "    n_heads=4,\n",
    "    d_k=64,\n",
    "    d_v=64,\n",
    "    dropout=0.1,\n",
    "    ORT_weight=1,  # you can adjust the weight values of arguments ORT_weight\n",
    "    # and MIT_weight to make the SAITS model focus more on one task. Usually you can just leave them to the default values, i.e. 1.\n",
    "    MIT_weight=1,\n",
    "    batch_size=32,\n",
    "    # here we set epochs=10 for a quick demo, you can set it to 100 or more for better performance\n",
    "    epochs=10,\n",
    "    # here we set patience=3 to early stop the training if the evaluting loss doesn't decrease for 3 epoches.\n",
    "    # You can leave it to defualt as None to disable early stopping.\n",
    "    patience=3,\n",
    "    # give the optimizer. Different from torch.optim.Optimizer, you don't have to specify model's parameters when\n",
    "    # initializing pypots.optim.Optimizer. You can also leave it to default. It will initilize an Adam optimizer with lr=0.001.\n",
    "    optimizer=Adam(lr=1e-3),\n",
    "    # this num_workers argument is for torch.utils.data.Dataloader. It's the number of subprocesses to use for data loading.\n",
    "    # Leaving it to default as 0 means data loading will be in the main process, i.e. there won't be subprocesses.\n",
    "    # You can increase it to >1 if you think your dataloading is a bottleneck to your model training speed\n",
    "    num_workers=0,\n",
    "    # just leave it to default as None, PyPOTS will automatically assign the best device for you.\n",
    "    # Set it as 'cpu' if you don't have CUDA devices. You can also set it to 'cuda:0' or 'cuda:1' if you have multiple CUDA devices, even parallelly on ['cuda:0', 'cuda:1']\n",
    "    device=None,\n",
    "    # set the path for saving tensorboard and trained model files\n",
    "    # only save the best model after training finished.\n",
    "    # You can also set it as \"better\" to save models performing better ever during training.\n",
    "    model_saving_strategy=\"best\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Inicialize new model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 19:12:21 [INFO]: No given device, using default device: cuda\n",
      "2025-01-29 19:12:21 [INFO]: Model files will be saved to tutorial_results/imputation/brits/20250129_T191221\n",
      "2025-01-29 19:12:21 [INFO]: Tensorboard file will be saved to tutorial_results/imputation/brits/20250129_T191221/tensorboard\n",
      "2025-01-29 19:12:21 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 255,344\n"
     ]
    }
   ],
   "source": [
    "brits = BRITS(\n",
    "    n_steps=physionet2012_dataset['n_steps'],\n",
    "    n_features=physionet2012_dataset['n_features'],\n",
    "    rnn_hidden_size=128,\n",
    "    batch_size=32,\n",
    "    # here we set epochs=10 for a quick demo, you can set it to 100 or more for better performance\n",
    "    epochs=10,\n",
    "    # here we set patience=3 to early stop the training if the evaluting loss doesn't decrease for 3 epoches.\n",
    "    # You can leave it to defualt as None to disable early stopping.\n",
    "    patience=3,\n",
    "    # give the optimizer. Different from torch.optim.Optimizer, you don't have to specify model's parameters when\n",
    "    # initializing pypots.optim.Optimizer. You can also leave it to default. It will initilize an Adam optimizer with lr=0.001.\n",
    "    optimizer=Adam(lr=1e-3),\n",
    "    # this num_workers argument is for torch.utils.data.Dataloader. It's the number of subprocesses to use for data loading.\n",
    "    # Leaving it to default as 0 means data loading will be in the main process, i.e. there won't be subprocesses.\n",
    "    # You can increase it to >1 if you think your dataloading is a bottleneck to your model training speed\n",
    "    num_workers=0,\n",
    "    # just leave it to default as None, PyPOTS will automatically assign the best device for you.\n",
    "    # Set it as 'cpu' if you don't have CUDA devices. You can also set it to 'cuda:0' or 'cuda:1' if you have multiple CUDA devices, even parallelly on ['cuda:0', 'cuda:1']\n",
    "    device=None,\n",
    "    # set the path for saving tensorboard and trained model files\n",
    "    saving_path=\"tutorial_results/imputation/brits\",\n",
    "    # only save the best model after training finished.\n",
    "    # You can also set it as \"better\" to save models performing better ever during training.\n",
    "    model_saving_strategy=\"best\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Inicialize existing model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 19:17:44 [INFO]: No given device, using default device: cpu\n",
      "2025-03-16 19:17:44 [WARNING]: ‼️ saving_path not given. Model files and tensorboard file will not be saved.\n",
      "2025-03-16 19:17:44 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 239,344\n"
     ]
    }
   ],
   "source": [
    "brits = BRITS(\n",
    "    n_steps=physionet2012_dataset['n_steps'],\n",
    "    n_features=physionet2012_dataset['n_features'],\n",
    "    rnn_hidden_size=128,\n",
    "    batch_size=32,\n",
    "    # here we set epochs=10 for a quick demo, you can set it to 100 or more for better performance\n",
    "    epochs=10,\n",
    "    # here we set patience=3 to early stop the training if the evaluting loss doesn't decrease for 3 epoches.\n",
    "    # You can leave it to defualt as None to disable early stopping.\n",
    "    patience=3,\n",
    "    # give the optimizer. Different from torch.optim.Optimizer, you don't have to specify model's parameters when\n",
    "    # initializing pypots.optim.Optimizer. You can also leave it to default. It will initilize an Adam optimizer with lr=0.001.\n",
    "    optimizer=Adam(lr=1e-3),\n",
    "    # this num_workers argument is for torch.utils.data.Dataloader. It's the number of subprocesses to use for data loading.\n",
    "    # Leaving it to default as 0 means data loading will be in the main process, i.e. there won't be subprocesses.\n",
    "    # You can increase it to >1 if you think your dataloading is a bottleneck to your model training speed\n",
    "    num_workers=0,\n",
    "    # just leave it to default as None, PyPOTS will automatically assign the best device for you.\n",
    "    # Set it as 'cpu' if you don't have CUDA devices. You can also set it to 'cuda:0' or 'cuda:1' if you have multiple CUDA devices, even parallelly on ['cuda:0', 'cuda:1']\n",
    "    device=None,\n",
    "    # set the path for saving tensorboard and trained model files\n",
    "    # only save the best model after training finished.\n",
    "    # You can also set it as \"better\" to save models performing better ever during training.\n",
    "    model_saving_strategy=\"best\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Inicialize new model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:06:16 [INFO]: No given device, using default device: cuda\n",
      "2025-02-10 23:06:16 [WARNING]: ‼️ saving_path not given. Model files and tensorboard file will not be saved.\n",
      "2025-02-10 23:06:16 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 1,258,517\n"
     ]
    }
   ],
   "source": [
    "us_gan = USGAN(\n",
    "    n_steps= physionet2012_dataset['n_steps'],\n",
    "    n_features= physionet2012_dataset['n_features'],\n",
    "    rnn_hidden_size=256,\n",
    "    lambda_mse=1,\n",
    "    dropout=0.1,\n",
    "    G_steps=1,\n",
    "    D_steps=1,\n",
    "    batch_size=32,\n",
    "    # here we set epochs=10 for a quick demo, you can set it to 100 or more for better performance\n",
    "    epochs=10,\n",
    "    # here we set patience=3 to early stop the training if the evaluting loss doesn't decrease for 3 epoches.\n",
    "    # You can leave it to defualt as None to disable early stopping.\n",
    "    patience=3,\n",
    "    # give the optimizer. Different from torch.optim.Optimizer, you don't have to specify model's parameters when\n",
    "    # initializing pypots.optim.Optimizer. You can also leave it to default. It will initilize an Adam optimizer with lr=0.001.\n",
    "    G_optimizer=Adam(lr=1e-3),\n",
    "    D_optimizer=Adam(lr=1e-3),\n",
    "    # this num_workers argument is for torch.utils.data.Dataloader. It's the number of subprocesses to use for data loading.\n",
    "    # Leaving it to default as 0 means data loading will be in the main process, i.e. there won't be subprocesses.\n",
    "    # You can increase it to >1 if you think your dataloading is a bottleneck to your model training speed\n",
    "    num_workers=0,\n",
    "    # just leave it to default as None, PyPOTS will automatically assign the best device for you.\n",
    "    # Set it as 'cpu' if you don't have CUDA devices. You can also set it to 'cuda:0' or 'cuda:1' if you have multiple CUDA devices, even parallelly on ['cuda:0', 'cuda:1']\n",
    "    device=None,\n",
    "    # set the path for saving tensorboard and trained model files\n",
    "    saving_path=\"tutorial_results/imputation/us_gan\",\n",
    "    # only save the best model after training finished.\n",
    "    # You can also set it as \"better\" to save models performing better ever during training.\n",
    "    model_saving_strategy=\"best\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Inicialize existing model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 19:17:49 [INFO]: No given device, using default device: cpu\n",
      "2025-03-16 19:17:49 [WARNING]: ‼️ saving_path not given. Model files and tensorboard file will not be saved.\n",
      "2025-03-16 19:17:49 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 1,258,517\n"
     ]
    }
   ],
   "source": [
    "us_gan = USGAN(\n",
    "    n_steps=physionet2012_dataset['n_steps'],\n",
    "    n_features=physionet2012_dataset['n_features'],\n",
    "    rnn_hidden_size=256,\n",
    "    lambda_mse=1,\n",
    "    dropout=0.1,\n",
    "    G_steps=1,\n",
    "    D_steps=1,\n",
    "    batch_size=32,\n",
    "    # here we set epochs=10 for a quick demo, you can set it to 100 or more for better performance\n",
    "    epochs=10,\n",
    "    # here we set patience=3 to early stop the training if the evaluting loss doesn't decrease for 3 epoches.\n",
    "    # You can leave it to defualt as None to disable early stopping.\n",
    "    patience=3,\n",
    "    # give the optimizer. Different from torch.optim.Optimizer, you don't have to specify model's parameters when\n",
    "    # initializing pypots.optim.Optimizer. You can also leave it to default. It will initilize an Adam optimizer with lr=0.001.\n",
    "    G_optimizer=Adam(lr=1e-3),\n",
    "    D_optimizer=Adam(lr=1e-3),\n",
    "    # this num_workers argument is for torch.utils.data.Dataloader. It's the number of subprocesses to use for data loading.\n",
    "    # Leaving it to default as 0 means data loading will be in the main process, i.e. there won't be subprocesses.\n",
    "    # You can increase it to >1 if you think your dataloading is a bottleneck to your model training speed\n",
    "    num_workers=0,\n",
    "    # just leave it to default as None, PyPOTS will automatically assign the best device for you.\n",
    "    # Set it as 'cpu' if you don't have CUDA devices. You can also set it to 'cuda:0' or 'cuda:1' if you have multiple CUDA devices, even parallelly on ['cuda:0', 'cuda:1']\n",
    "    device=None,\n",
    "    # set the path for saving tensorboard and trained model files\n",
    "    # only save the best model after training finished.\n",
    "    # You can also set it as \"better\" to save models performing better ever during training.\n",
    "    model_saving_strategy=\"best\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Inicialize new model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:06:18 [INFO]: No given device, using default device: cuda\n",
      "2025-02-10 23:06:18 [WARNING]: ‼️ saving_path not given. Model files and tensorboard file will not be saved.\n",
      "2025-02-10 23:06:18 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 229,652\n"
     ]
    }
   ],
   "source": [
    "gp_vae = GPVAE(\n",
    "    n_steps=physionet2012_dataset['n_steps'],\n",
    "    n_features=physionet2012_dataset['n_features'],\n",
    "    latent_size=37,\n",
    "    encoder_sizes=(128,128),\n",
    "    decoder_sizes=(256,256),\n",
    "    kernel=\"cauchy\",\n",
    "    beta=0.2,\n",
    "    M=1,\n",
    "    K=1,\n",
    "    sigma=1.005,\n",
    "    length_scale=7.0,\n",
    "    kernel_scales=1,\n",
    "    window_size=24,\n",
    "    batch_size=32,\n",
    "    # here we set epochs=10 for a quick demo, you can set it to 100 or more for better performance\n",
    "    epochs=10,\n",
    "    # here we set patience=3 to early stop the training if the evaluting loss doesn't decrease for 3 epoches.\n",
    "    # You can leave it to defualt as None to disable early stopping.\n",
    "    patience=3,\n",
    "    # give the optimizer. Different from torch.optim.Optimizer, you don't have to specify model's parameters when\n",
    "    # initializing pypots.optim.Optimizer. You can also leave it to default. It will initilize an Adam optimizer with lr=0.001.\n",
    "    optimizer=Adam(lr=1e-3),\n",
    "    # this num_workers argument is for torch.utils.data.Dataloader. It's the number of subprocesses to use for data loading.\n",
    "    # Leaving it to default as 0 means data loading will be in the main process, i.e. there won't be subprocesses.\n",
    "    # You can increase it to >1 if you think your dataloading is a bottleneck to your model training speed\n",
    "    num_workers=0,\n",
    "    # just leave it to default as None, PyPOTS will automatically assign the best device for you.\n",
    "    # Set it as 'cpu' if you don't have CUDA devices. You can also set it to 'cuda:0' or 'cuda:1' if you have multiple CUDA devices, even parallelly on ['cuda:0', 'cuda:1']\n",
    "    device=None,\n",
    "    # set the path for saving tensorboard and trained model files\n",
    "    saving_path=\"tutorial_results/imputation/gp_vae\",\n",
    "    # only save the best model after training finished.\n",
    "    # You can also set it as \"better\" to save models performing better ever during training.\n",
    "    model_saving_strategy=\"best\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Inicialize existing model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 19:17:54 [INFO]: No given device, using default device: cpu\n",
      "2025-03-16 19:17:54 [WARNING]: ‼️ saving_path not given. Model files and tensorboard file will not be saved.\n",
      "2025-03-16 19:17:54 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 229,652\n"
     ]
    }
   ],
   "source": [
    "gp_vae = GPVAE(\n",
    "    n_steps=physionet2012_dataset['n_steps'],\n",
    "    n_features=physionet2012_dataset['n_features'],\n",
    "    latent_size=37,\n",
    "    encoder_sizes=(128,128),\n",
    "    decoder_sizes=(256,256),\n",
    "    kernel=\"cauchy\",\n",
    "    beta=0.2,\n",
    "    M=1,\n",
    "    K=1,\n",
    "    sigma=1.005,\n",
    "    length_scale=7.0,\n",
    "    kernel_scales=1,\n",
    "    window_size=24,\n",
    "    batch_size=32,\n",
    "    # here we set epochs=10 for a quick demo, you can set it to 100 or more for better performance\n",
    "    epochs=10,\n",
    "    # here we set patience=3 to early stop the training if the evaluting loss doesn't decrease for 3 epoches.\n",
    "    # You can leave it to defualt as None to disable early stopping.\n",
    "    patience=3,\n",
    "    # give the optimizer. Different from torch.optim.Optimizer, you don't have to specify model's parameters when\n",
    "    # initializing pypots.optim.Optimizer. You can also leave it to default. It will initilize an Adam optimizer with lr=0.001.\n",
    "    optimizer=Adam(lr=1e-3),\n",
    "    # this num_workers argument is for torch.utils.data.Dataloader. It's the number of subprocesses to use for data loading.\n",
    "    # Leaving it to default as 0 means data loading will be in the main process, i.e. there won't be subprocesses.\n",
    "    # You can increase it to >1 if you think your dataloading is a bottleneck to your model training speed\n",
    "    num_workers=0,\n",
    "    # just leave it to default as None, PyPOTS will automatically assign the best device for you.\n",
    "    # Set it as 'cpu' if you don't have CUDA devices. You can also set it to 'cuda:0' or 'cuda:1' if you have multiple CUDA devices, even parallelly on ['cuda:0', 'cuda:1']\n",
    "    device=None,\n",
    "    # set the path for saving tensorboard and trained model files\n",
    "    # only save the best model after training finished.\n",
    "    # You can also set it as \"better\" to save models performing better ever during training.\n",
    "    model_saving_strategy=\"best\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Inicialize new model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:06:21 [INFO]: No given device, using default device: cuda\n",
      "2025-02-10 23:06:21 [WARNING]: ‼️ saving_path not given. Model files and tensorboard file will not be saved.\n",
      "2025-02-10 23:06:21 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 107,951\n"
     ]
    }
   ],
   "source": [
    "mrnn = MRNN(\n",
    "    n_steps=physionet2012_dataset['n_steps'],\n",
    "    n_features=physionet2012_dataset['n_features'],\n",
    "    rnn_hidden_size=128,\n",
    "\n",
    "    # here we set epochs=10 for a quick demo, you can set it to 100 or more for better performance\n",
    "    epochs=10,\n",
    "    # here we set patience=3 to early stop the training if the evaluting loss doesn't decrease for 3 epoches.\n",
    "    # You can leave it to defualt as None to disable early stopping.\n",
    "    patience=3,\n",
    "    # give the optimizer. Different from torch.optim.Optimizer, you don't have to specify model's parameters when\n",
    "    # initializing pypots.optim.Optimizer. You can also leave it to default. It will initilize an Adam optimizer with lr=0.001.\n",
    "    optimizer=Adam(lr=1e-3),\n",
    "    # this num_workers argument is for torch.utils.data.Dataloader. It's the number of subprocesses to use for data loading.\n",
    "    # Leaving it to default as 0 means data loading will be in the main process, i.e. there won't be subprocesses.\n",
    "    # You can increase it to >1 if you think your dataloading is a bottleneck to your model training speed\n",
    "    num_workers=0,\n",
    "    # just leave it to default as None, PyPOTS will automatically assign the best device for you.\n",
    "    # Set it as 'cpu' if you don't have CUDA devices. You can also set it to 'cuda:0' or 'cuda:1' if you have multiple CUDA devices, even parallelly on ['cuda:0', 'cuda:1']\n",
    "    device=None,\n",
    "    # set the path for saving tensorboard and trained model files\n",
    "    saving_path=\"tutorial_results/imputation/mrnn\",\n",
    "    # only save the best model after training finished.\n",
    "    # You can also set it as \"better\" to save models performing better ever during training.\n",
    "    model_saving_strategy=\"best\",\n",
    ") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Inicialize existing model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 19:17:59 [INFO]: No given device, using default device: cpu\n",
      "2025-03-16 19:17:59 [WARNING]: ‼️ saving_path not given. Model files and tensorboard file will not be saved.\n",
      "2025-03-16 19:17:59 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 107,951\n"
     ]
    }
   ],
   "source": [
    "mrnn = MRNN(\n",
    "    n_steps=physionet2012_dataset['n_steps'],\n",
    "    n_features=physionet2012_dataset['n_features'],\n",
    "    rnn_hidden_size=128,\n",
    "\n",
    "    # here we set epochs=10 for a quick demo, you can set it to 100 or more for better performance\n",
    "    epochs=10,\n",
    "    # here we set patience=3 to early stop the training if the evaluting loss doesn't decrease for 3 epoches.\n",
    "    # You can leave it to defualt as None to disable early stopping.\n",
    "    patience=3,\n",
    "    # give the optimizer. Different from torch.optim.Optimizer, you don't have to specify model's parameters when\n",
    "    # initializing pypots.optim.Optimizer. You can also leave it to default. It will initilize an Adam optimizer with lr=0.001.\n",
    "    optimizer=Adam(lr=1e-3),\n",
    "    # this num_workers argument is for torch.utils.data.Dataloader. It's the number of subprocesses to use for data loading.\n",
    "    # Leaving it to default as 0 means data loading will be in the main process, i.e. there won't be subprocesses.\n",
    "    # You can increase it to >1 if you think your dataloading is a bottleneck to your model training speed\n",
    "    num_workers=0,\n",
    "    # just leave it to default as None, PyPOTS will automatically assign the best device for you.\n",
    "    # Set it as 'cpu' if you don't have CUDA devices. You can also set it to 'cuda:0' or 'cuda:1' if you have multiple CUDA devices, even parallelly on ['cuda:0', 'cuda:1']\n",
    "    device=None,\n",
    "    # set the path for saving tensorboard and trained model files\n",
    "    # only save the best model after training finished.\n",
    "    # You can also set it as \"better\" to save models performing better ever during training.\n",
    "    model_saving_strategy=\"best\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 23:03:50 [INFO]: Epoch 001 - training loss (MSE): 0.7958, validation MSE: 6.7265\n",
      "2025-03-17 23:03:59 [INFO]: Epoch 002 - training loss (MSE): 0.5808, validation MSE: 6.6878\n",
      "2025-03-17 23:04:09 [INFO]: Epoch 003 - training loss (MSE): 0.5045, validation MSE: 6.6668\n",
      "2025-03-17 23:04:18 [INFO]: Epoch 004 - training loss (MSE): 0.4531, validation MSE: 6.6624\n",
      "2025-03-17 23:04:28 [INFO]: Epoch 005 - training loss (MSE): 0.4467, validation MSE: 6.6489\n",
      "2025-03-17 23:04:38 [INFO]: Epoch 006 - training loss (MSE): 0.4151, validation MSE: 6.6447\n",
      "2025-03-17 23:04:47 [INFO]: Epoch 007 - training loss (MSE): 0.4244, validation MSE: 6.6355\n",
      "2025-03-17 23:04:57 [INFO]: Epoch 008 - training loss (MSE): 0.4267, validation MSE: 6.7094\n",
      "2025-03-17 23:05:06 [INFO]: Epoch 009 - training loss (MSE): 0.3915, validation MSE: 6.6419\n",
      "2025-03-17 23:05:16 [INFO]: Epoch 010 - training loss (MSE): 0.4287, validation MSE: 6.6349\n",
      "2025-03-17 23:05:16 [INFO]: Finished training. The best model is from epoch#10.\n",
      "2025-03-17 23:05:16 [INFO]: Saved the model to tutorial_results/imputation/saits/20250317_T230327/SAITS.pypots\n"
     ]
    }
   ],
   "source": [
    "# train the model on the training set, and validate it on the validating set to select the best model for testing in the next step\n",
    "saits.fit(train_set=dataset_for_training, val_set=dataset_for_validating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 19:13:29 [INFO]: Epoch 001 - training loss: 0.8504, validation loss: 0.2889\n",
      "2025-01-29 19:13:29 [INFO]: Saved the model to tutorial_results/imputation/brits/20250129_T191221/BRITS_epoch1_loss0.28890601024031637.pypots\n",
      "2025-01-29 19:14:17 [INFO]: Epoch 002 - training loss: 0.5925, validation loss: 0.2504\n",
      "2025-01-29 19:14:17 [INFO]: Saved the model to tutorial_results/imputation/brits/20250129_T191221/BRITS_epoch2_loss0.25044039537509283.pypots\n",
      "2025-01-29 19:15:06 [INFO]: Epoch 003 - training loss: 0.5444, validation loss: 0.2404\n",
      "2025-01-29 19:15:06 [INFO]: Saved the model to tutorial_results/imputation/brits/20250129_T191221/BRITS_epoch3_loss0.24043585633238157.pypots\n",
      "2025-01-29 19:15:55 [INFO]: Epoch 004 - training loss: 0.5230, validation loss: 0.2346\n",
      "2025-01-29 19:15:55 [INFO]: Saved the model to tutorial_results/imputation/brits/20250129_T191221/BRITS_epoch4_loss0.23458528518676758.pypots\n",
      "2025-01-29 19:16:43 [INFO]: Epoch 005 - training loss: 0.5095, validation loss: 0.2312\n",
      "2025-01-29 19:16:43 [INFO]: Saved the model to tutorial_results/imputation/brits/20250129_T191221/BRITS_epoch5_loss0.231178251405557.pypots\n",
      "2025-01-29 19:17:32 [INFO]: Epoch 006 - training loss: 0.4983, validation loss: 0.2307\n",
      "2025-01-29 19:17:32 [INFO]: Saved the model to tutorial_results/imputation/brits/20250129_T191221/BRITS_epoch6_loss0.23071187660098075.pypots\n",
      "2025-01-29 19:18:21 [INFO]: Epoch 007 - training loss: 0.4895, validation loss: 0.2310\n",
      "2025-01-29 19:19:10 [INFO]: Epoch 008 - training loss: 0.4830, validation loss: 0.2328\n",
      "2025-01-29 19:19:59 [INFO]: Epoch 009 - training loss: 0.4766, validation loss: 0.2355\n",
      "2025-01-29 19:19:59 [INFO]: Exceeded the training patience. Terminating the training procedure...\n",
      "2025-01-29 19:19:59 [INFO]: Finished training. The best model is from epoch#6.\n",
      "2025-01-29 19:19:59 [INFO]: Saved the model to tutorial_results/imputation/brits/20250129_T191221/BRITS.pypots\n"
     ]
    }
   ],
   "source": [
    "# train the model on the training set, and validate it on the validating set to select the best model for testing in the next step\n",
    "brits.fit(train_set=dataset_for_training, val_set=dataset_for_validating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 19:18:03 [INFO]: Model loaded successfully from tutorial_results/imputation/saits/standard/SAITS.pypots\n"
     ]
    }
   ],
   "source": [
    "saits.load(\"tutorial_results/imputation/saits/standard/SAITS.pypots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 19:18:06 [INFO]: Model loaded successfully from tutorial_results/imputation/brits/standard/BRITS.pypots\n"
     ]
    }
   ],
   "source": [
    "brits.load(\"tutorial_results/imputation/brits/standard/BRITS.pypots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 19:18:07 [INFO]: Model loaded successfully from tutorial_results/imputation/us_gan/standard/USGAN.pypots\n"
     ]
    }
   ],
   "source": [
    "us_gan.load(\"tutorial_results/imputation/us_gan/standard/USGAN.pypots\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 19:18:09 [INFO]: Model loaded successfully from tutorial_results/imputation/gp_vae/standard/GPVAE.pypots\n"
     ]
    }
   ],
   "source": [
    "gp_vae.load(\"tutorial_results/imputation/gp_vae/standard/GPVAE.pypots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 19:18:12 [INFO]: Model loaded successfully from tutorial_results/imputation/mrnn/standard/MRNN.pypots\n"
     ]
    }
   ],
   "source": [
    "mrnn.load(\"tutorial_results/imputation/mrnn/standard/MRNN.pypots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The testing stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the testing stage, impute the originally-missing values and artificially-missing values in the test set\n",
    "saits_imputation = []\n",
    "for value in  dataset_for_testing.values():\n",
    "   _dict = {'X':value}\n",
    "   saits_results = saits.predict(_dict)\n",
    "   saits_imputation.append(saits_results[\"imputation\"])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the testing stage, impute the originally-missing values and artificially-missing values in the test set\n",
    "brits_imputation = []\n",
    "for value in dataset_for_testing.values():\n",
    "    _dict = {'X':value}\n",
    "    brits_results = brits.predict(_dict)\n",
    "    brits_imputation.append(brits_results[\"imputation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "usgan_imputation = []\n",
    "for value in  dataset_for_testing.values():\n",
    "   _dict = {'X':value}\n",
    "   usgan_results = us_gan.predict(_dict)\n",
    "   usgan_imputation.append(usgan_results[\"imputation\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpvae_imputation = []\n",
    "for value in  dataset_for_testing.values():\n",
    "   _dict = {'X':value}\n",
    "   gpvae_results = gp_vae.predict(_dict)\n",
    "   gpvae_imputation.append(gpvae_results[\"imputation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrnn_imputation = []\n",
    "for value in  dataset_for_testing.values():\n",
    "   _dict = {'X':value}\n",
    "   mrnn_results = mrnn.predict(_dict)\n",
    "   mrnn_imputation.append(mrnn_results[\"imputation\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate mean absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_mae_saits = []\n",
    "for i in range(len(saits_imputation)):\n",
    "    testing_mae_saits.append(calc_mae(saits_imputation[i], test_X_ori[i], test_X_indicating_mask[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_mae_brits = []\n",
    "for i in range(len(brits_imputation)):\n",
    "    testing_mae_brits.append(calc_mae(brits_imputation[i], test_X_ori[i], test_X_indicating_mask[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_mae_usgan = []\n",
    "for i in range(len(usgan_imputation)):\n",
    "    testing_mae_usgan.append(calc_mae(usgan_imputation[i], test_X_ori[i], test_X_indicating_mask[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(gpvae_imputation)):\n",
    "    gpvae_imputation[i] = gpvae_imputation[i].reshape(len(gpvae_imputation[i]), 48, 37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_mae_gpvae = []\n",
    "for i in range(len(gpvae_imputation)):\n",
    "    testing_mae_gpvae.append(calc_mae(gpvae_imputation[i], test_X_ori[i], test_X_indicating_mask[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_mae_mrnn = []\n",
    "for i in range(len(mrnn_imputation)):\n",
    "    testing_mae_mrnn.append(calc_mae(mrnn_imputation[i], test_X_ori[i], test_X_indicating_mask[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgroups = [\"General\", \"Female\", \"Male\", \"Undefined Gender\", \"+65\", \"-65\", \"ICUType 1\", \"ICUType 2\", \"ICUType 3\", \"ICUType 4\", \"Undefined classification\", \"Low Weight\", \"Normal Weight\", \"Overweight\", \"Obesity 1\", \"Obesity 2\", \"Obesity 3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAITS - MAE\n",
      "-------------\n",
      "General : 0.27077346305383765\n",
      "Female : 0.27205880564407836\n",
      "Male : 0.2749153674534257\n",
      "Undefined Gender : 0.20100186339744913\n",
      "+65 : 0.2667339001575028\n",
      "-65 : 0.27959884451842193\n",
      "ICUType 1 : 0.28883602706039174\n",
      "ICUType 2 : 0.2429101299201823\n",
      "ICUType 3 : 0.2876700677245509\n",
      "ICUType 4 : 0.2775607868042399\n",
      "Undefined classification : 0.2814047523152634\n",
      "Low Weight : 0.2901282325497619\n",
      "Normal Weight : 0.25461907386388605\n",
      "Overweight : 0.25833916107879573\n",
      "Obesity 1 : 0.2786189352851397\n",
      "Obesity 2 : 0.2568809183361219\n",
      "Obesity 3 : 0.2736831699961278\n"
     ]
    }
   ],
   "source": [
    "print(\"SAITS - MAE\")\n",
    "print(\"-------------\")\n",
    "for i in range(len(subgroups)):\n",
    "    print(subgroups[i], \":\" ,testing_mae_saits[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRITS - MAE\n",
      "-------------\n",
      "General : 0.20607649494742675\n",
      "Female : 0.20614220432360486\n",
      "Male : 0.21246684469801871\n",
      "Undefined Gender : 0.18272824533494633\n",
      "+65 : 0.20458278834580312\n",
      "-65 : 0.21627359080249212\n",
      "ICUType 1 : 0.220299073686516\n",
      "ICUType 2 : 0.1808477823544893\n",
      "ICUType 3 : 0.22441586013095977\n",
      "ICUType 4 : 0.20966047499437565\n",
      "Undefined classification : 0.21801499897060275\n",
      "Low Weight : 0.24078274437854238\n",
      "Normal Weight : 0.195872946252596\n",
      "Overweight : 0.19804599357933922\n",
      "Obesity 1 : 0.19122453585431926\n",
      "Obesity 2 : 0.2035281786613216\n",
      "Obesity 3 : 0.2143222467284282\n"
     ]
    }
   ],
   "source": [
    "print(\"BRITS - MAE\")\n",
    "print(\"-------------\")\n",
    "for i in range(len(subgroups)):\n",
    "    print(subgroups[i], \":\" ,testing_mae_brits[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USGAN - MAE\n",
      "-------------\n",
      "General : 0.2725404672962992\n",
      "Female : 0.27515345338175035\n",
      "Male : 0.2759156782410606\n",
      "Undefined Gender : 0.22719787038605313\n",
      "+65 : 0.2703022819200602\n",
      "-65 : 0.28051891797636347\n",
      "ICUType 1 : 0.29337843510987965\n",
      "ICUType 2 : 0.23865748003371157\n",
      "ICUType 3 : 0.29412443520709886\n",
      "ICUType 4 : 0.2800859210695823\n",
      "Undefined classification : 0.2877627249325782\n",
      "Low Weight : 0.30363618669583015\n",
      "Normal Weight : 0.2588177315143253\n",
      "Overweight : 0.2544338181108165\n",
      "Obesity 1 : 0.2758376945836133\n",
      "Obesity 2 : 0.2619401389587843\n",
      "Obesity 3 : 0.2693813004105881\n"
     ]
    }
   ],
   "source": [
    "print(\"USGAN - MAE\")\n",
    "print(\"-------------\")\n",
    "for i in range(len(subgroups)):\n",
    "    print(subgroups[i], \":\" ,testing_mae_usgan[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRNN - MAE\n",
      "-------------\n",
      "General : 0.6713145721873255\n",
      "Female : 0.6886168215267683\n",
      "Male : 0.6593698528405196\n",
      "Undefined Gender : 0.5788306694697075\n",
      "+65 : 0.6680155576961296\n",
      "-65 : 0.6851731084848083\n",
      "ICUType 1 : 0.7000602620167663\n",
      "ICUType 2 : 0.5960496586403451\n",
      "ICUType 3 : 0.7305747176870081\n",
      "ICUType 4 : 0.6660171755623768\n",
      "Undefined classification : 0.6998902963878201\n",
      "Low Weight : 0.7413824045826151\n",
      "Normal Weight : 0.6484704845721746\n",
      "Overweight : 0.6258698324694673\n",
      "Obesity 1 : 0.6399939492108968\n",
      "Obesity 2 : 0.6628144867515143\n",
      "Obesity 3 : 0.7372770171765964\n"
     ]
    }
   ],
   "source": [
    "print(\"MRNN - MAE\")\n",
    "print(\"-------------\")\n",
    "for i in range(len(subgroups)):\n",
    "    print(subgroups[i], \":\" ,testing_mae_mrnn[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPVAE - MAE\n",
      "-------------\n",
      "General : 0.454358819819243\n",
      "Female : 0.45964569560182006\n",
      "Male : 0.4539033170525852\n",
      "Undefined Gender : 0.3952713921281636\n",
      "+65 : 0.45158590664180026\n",
      "-65 : 0.4686480177725102\n",
      "ICUType 1 : 0.4759892460652797\n",
      "ICUType 2 : 0.39423516109862916\n",
      "ICUType 3 : 0.49689965362643795\n",
      "ICUType 4 : 0.46005345089771515\n",
      "Undefined classification : 0.47611340106275457\n",
      "Low Weight : 0.5194780203246361\n",
      "Normal Weight : 0.4300186668030726\n",
      "Overweight : 0.4300886671089587\n",
      "Obesity 1 : 0.45186196738172746\n",
      "Obesity 2 : 0.4501944866258905\n",
      "Obesity 3 : 0.4661876578901662\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"GPVAE - MAE\")\n",
    "print(\"-------------\")\n",
    "for i in range(len(subgroups)):\n",
    "    print(subgroups[i], \":\" ,testing_mae_gpvae[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
