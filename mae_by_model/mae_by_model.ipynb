{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61a67522",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "770032fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 22:38:30.990826: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746927511.012789  697516 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746927511.019416  697516 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-10 22:38:31.041270: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/local/lib/python3.11/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "████████╗██╗███╗   ███╗███████╗    ███████╗███████╗██████╗ ██╗███████╗███████╗    █████╗ ██╗\n",
      "╚══██╔══╝██║████╗ ████║██╔════╝    ██╔════╝██╔════╝██╔══██╗██║██╔════╝██╔════╝   ██╔══██╗██║\n",
      "   ██║   ██║██╔████╔██║█████╗█████╗███████╗█████╗  ██████╔╝██║█████╗  ███████╗   ███████║██║\n",
      "   ██║   ██║██║╚██╔╝██║██╔══╝╚════╝╚════██║██╔══╝  ██╔══██╗██║██╔══╝  ╚════██║   ██╔══██║██║\n",
      "   ██║   ██║██║ ╚═╝ ██║███████╗    ███████║███████╗██║  ██║██║███████╗███████║██╗██║  ██║██║\n",
      "   ╚═╝   ╚═╝╚═╝     ╚═╝╚══════╝    ╚══════╝╚══════╝╚═╝  ╚═╝╚═╝╚══════╝╚══════╝╚═╝╚═╝  ╚═╝╚═╝\n",
      "ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai \u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pypots\n",
    "import numpy as np\n",
    "import benchpots\n",
    "import matplotlib.pyplot as plt\n",
    "from pypots.optim import Adam\n",
    "from pypots.imputation import SAITS, BRITS, USGAN, GPVAE, MRNN\n",
    "from pypots.utils.random import set_random_seed\n",
    "from functions.toolkits import toolkits\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from MAEModify.error import calc_mae\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62408df9",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c285b751",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 22:38:34 [INFO]: Have set the random seed as 2022 for numpy and pytorch.\n",
      "2025-05-10 22:38:34 [INFO]: You're using dataset physionet_2012, please cite it properly in your work. You can find its reference information at the below link: \n",
      "https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/physionet_2012\n",
      "2025-05-10 22:38:34 [INFO]: Dataset physionet_2012 has already been downloaded. Processing directly...\n",
      "2025-05-10 22:38:34 [INFO]: Dataset physionet_2012 has already been cached. Loading from cache directly...\n",
      "2025-05-10 22:38:34 [INFO]: Loaded successfully!\n",
      "2025-05-10 22:38:51 [WARNING]: Note that physionet_2012 has sparse observations in the time series, hence we don't add additional missing values to the training dataset. \n",
      "2025-05-10 22:38:51 [INFO]: 68807 values masked out in the val set as ground truth, take 9.97% of the original observed values\n",
      "2025-05-10 22:38:51 [INFO]: 86319 values masked out in the test set as ground truth, take 9.99% of the original observed values\n",
      "2025-05-10 22:38:51 [INFO]: Total sample number: 11988\n",
      "2025-05-10 22:38:51 [INFO]: Training set size: 7671 (63.99%)\n",
      "2025-05-10 22:38:51 [INFO]: Validation set size: 1918 (16.00%)\n",
      "2025-05-10 22:38:51 [INFO]: Test set size: 2399 (20.01%)\n",
      "2025-05-10 22:38:51 [INFO]: Number of steps: 48\n",
      "2025-05-10 22:38:51 [INFO]: Number of features: 37\n",
      "2025-05-10 22:38:51 [INFO]: Train set missing rate: 79.70%\n",
      "2025-05-10 22:38:51 [INFO]: Validating set missing rate: 81.75%\n",
      "2025-05-10 22:38:51 [INFO]: Test set missing rate: 81.75%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['n_classes', 'n_steps', 'n_features', 'scaler', 'train_X', 'train_y', 'train_ICUType', 'val_X', 'val_y', 'val_ICUType', 'test_X', 'test_y', 'test_ICUType', 'val_X_ori', 'test_X_ori'])\n"
     ]
    }
   ],
   "source": [
    "set_random_seed()\n",
    "physionet2012_dataset = benchpots.datasets.preprocess_physionet2012(subset=\"all\", rate=0.1)\n",
    "print(physionet2012_dataset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec18197f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_for_training = {\n",
    "    \"X\": physionet2012_dataset['train_X'],\n",
    "}\n",
    "\n",
    "dataset_for_validating = {\n",
    "    \"X\": physionet2012_dataset['val_X'],\n",
    "    \"X_ori\": physionet2012_dataset['val_X_ori'],\n",
    "}\n",
    "\n",
    "dataset_for_testing = {\n",
    "    \"X\": physionet2012_dataset['test_X'],\n",
    "}\n",
    "\n",
    "test_X_indicating_mask = np.isnan(physionet2012_dataset['test_X_ori']) ^ np.isnan(physionet2012_dataset['test_X'])\n",
    "test_X_ori = np.nan_to_num(physionet2012_dataset['test_X_ori']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c00b23",
   "metadata": {},
   "source": [
    "# Train/Load Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82818d3",
   "metadata": {},
   "source": [
    "## SAITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0544ec91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 22:38:51 [INFO]: No given device, using default device: cpu\n",
      "2025-05-10 22:38:51 [WARNING]: ‼️ saving_path not given. Model files and tensorboard file will not be saved.\n",
      "2025-05-10 22:38:51 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-05-10 22:38:51 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-05-10 22:38:51 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 720,182\n"
     ]
    }
   ],
   "source": [
    "saits = SAITS(\n",
    "    n_steps=physionet2012_dataset['n_steps'],\n",
    "    n_features=physionet2012_dataset['n_features'],\n",
    "    n_layers=1,\n",
    "    d_model=256,\n",
    "    d_ffn=128,\n",
    "    n_heads=4,\n",
    "    d_k=64,\n",
    "    d_v=64,\n",
    "    dropout=0.1,\n",
    "    ORT_weight=1,  \n",
    "    MIT_weight=1,\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    patience=3,\n",
    "    optimizer=Adam(lr=1e-3),\n",
    "    num_workers=0,\n",
    "    device=None,\n",
    "    model_saving_strategy=\"best\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7755ef6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 22:38:51 [INFO]: Model loaded successfully from ../mae/tutorial_results/imputation/saits/20250422_T181642/SAITS.pypots\n"
     ]
    }
   ],
   "source": [
    "saits.load(\"../mae/tutorial_results/imputation/saits/20250422_T181642/SAITS.pypots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7135537",
   "metadata": {},
   "source": [
    "## BRITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "160b68c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 22:38:51 [INFO]: No given device, using default device: cpu\n",
      "2025-05-10 22:38:51 [WARNING]: ‼️ saving_path not given. Model files and tensorboard file will not be saved.\n",
      "2025-05-10 22:38:51 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-05-10 22:38:51 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-05-10 22:38:51 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 239,344\n"
     ]
    }
   ],
   "source": [
    "brits = BRITS(\n",
    "    n_steps=physionet2012_dataset['n_steps'],\n",
    "    n_features=physionet2012_dataset['n_features'],\n",
    "    rnn_hidden_size=128,\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    patience=3,\n",
    "    optimizer=Adam(lr=1e-3),\n",
    "    num_workers=0,\n",
    "    device=None,\n",
    "    model_saving_strategy=\"best\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94e7f531",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 22:38:51 [INFO]: Model loaded successfully from ../mae/tutorial_results/imputation/brits/20250422_T181643/BRITS.pypots\n"
     ]
    }
   ],
   "source": [
    "brits.load(\"../mae/tutorial_results/imputation/brits/20250422_T181643/BRITS.pypots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b70c68",
   "metadata": {},
   "source": [
    "## US-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb04ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 22:38:51 [INFO]: No given device, using default device: cpu\n",
      "2025-05-10 22:38:51 [WARNING]: ‼️ saving_path not given. Model files and tensorboard file will not be saved.\n",
      "2025-05-10 22:38:51 [INFO]: USGAN initialized with the given hyperparameters, the number of trainable parameters: 1,258,517\n"
     ]
    }
   ],
   "source": [
    "us_gan = USGAN(\n",
    "    n_steps=physionet2012_dataset['n_steps'],\n",
    "    n_features=physionet2012_dataset['n_features'],\n",
    "    rnn_hidden_size=256,\n",
    "    lambda_mse=1,\n",
    "    dropout=0.1,\n",
    "    G_steps=1,\n",
    "    D_steps=1,\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    patience=3,\n",
    "    G_optimizer=Adam(lr=1e-3),\n",
    "    D_optimizer=Adam(lr=1e-3),\n",
    "    num_workers=0,\n",
    "    device=None,\n",
    "    model_saving_strategy=\"best\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e6308e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 22:38:53 [INFO]: Model loaded successfully from ../mae/tutorial_results/imputation/us_gan/20250422_T181643/USGAN.pypots\n"
     ]
    }
   ],
   "source": [
    "us_gan.load(\"../mae/tutorial_results/imputation/us_gan/20250422_T181643/USGAN.pypots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c609a0",
   "metadata": {},
   "source": [
    "## GP-VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c0b8e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 22:38:58 [INFO]: No given device, using default device: cpu\n",
      "2025-05-10 22:38:58 [WARNING]: ‼️ saving_path not given. Model files and tensorboard file will not be saved.\n",
      "2025-05-10 22:38:58 [INFO]: GPVAE initialized with the given hyperparameters, the number of trainable parameters: 229,652\n"
     ]
    }
   ],
   "source": [
    "gp_vae = GPVAE(\n",
    "    n_steps=physionet2012_dataset['n_steps'],\n",
    "    n_features=physionet2012_dataset['n_features'],\n",
    "    latent_size=37,\n",
    "    encoder_sizes=(128,128),\n",
    "    decoder_sizes=(256,256),\n",
    "    kernel=\"cauchy\",\n",
    "    beta=0.2,\n",
    "    M=1,\n",
    "    K=1,\n",
    "    sigma=1.005,\n",
    "    length_scale=7.0,\n",
    "    kernel_scales=1,\n",
    "    window_size=24,\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    patience=3,\n",
    "    optimizer=Adam(lr=1e-3),\n",
    "    num_workers=0,\n",
    "    device=None,\n",
    "    model_saving_strategy=\"best\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e1991e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 22:39:00 [INFO]: Model loaded successfully from ../mae/tutorial_results/imputation/gp_vae/20250422_T181643/GPVAE.pypots\n"
     ]
    }
   ],
   "source": [
    "gp_vae.load(\"../mae/tutorial_results/imputation/gp_vae/20250422_T181643/GPVAE.pypots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858e155d",
   "metadata": {},
   "source": [
    "## MRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fa6e07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 22:39:02 [INFO]: No given device, using default device: cpu\n",
      "2025-05-10 22:39:02 [WARNING]: ‼️ saving_path not given. Model files and tensorboard file will not be saved.\n",
      "2025-05-10 22:39:02 [INFO]: Using customized RMSE as the training loss function.\n",
      "2025-05-10 22:39:02 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-05-10 22:39:02 [INFO]: MRNN initialized with the given hyperparameters, the number of trainable parameters: 107,951\n"
     ]
    }
   ],
   "source": [
    "mrnn = MRNN(\n",
    "    n_steps=physionet2012_dataset['n_steps'],\n",
    "    n_features=physionet2012_dataset['n_features'],\n",
    "    rnn_hidden_size=128,\n",
    "    epochs=10,\n",
    "    patience=3,\n",
    "    optimizer=Adam(lr=1e-3),\n",
    "    num_workers=0,\n",
    "    device=None,\n",
    "    model_saving_strategy=\"best\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6028541",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 22:39:04 [INFO]: Model loaded successfully from ../mae/tutorial_results/imputation/mrnn/20250422_T181643/MRNN.pypots\n"
     ]
    }
   ],
   "source": [
    "mrnn.load(\"../mae/tutorial_results/imputation/mrnn/20250422_T181643/MRNN.pypots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a0ce15",
   "metadata": {},
   "source": [
    "# Imputation models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8288cf",
   "metadata": {},
   "source": [
    "## SAITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e067a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "saits_results = saits.predict(dataset_for_testing)\n",
    "saits_imputation = saits_results[\"imputation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810a4f1c",
   "metadata": {},
   "source": [
    "## BRITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a039628",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m brits_results = \u001b[43mbrits\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_for_testing\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m brits_imputation = brits_results[\u001b[33m\"\u001b[39m\u001b[33mimputation\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/pypots/imputation/brits/model.py:262\u001b[39m, in \u001b[36mBRITS.predict\u001b[39m\u001b[34m(self, test_set, file_type)\u001b[39m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(test_dataloader):\n\u001b[32m    261\u001b[39m     inputs = \u001b[38;5;28mself\u001b[39m._assemble_input_for_testing(data)\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    263\u001b[39m     dict_result_collector.append(results)\n\u001b[32m    265\u001b[39m \u001b[38;5;66;03m# Step 3: output collection and return\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/pypots/imputation/brits/core.py:71\u001b[39m, in \u001b[36m_BRITS.forward\u001b[39m\u001b[34m(self, inputs, calc_criterion)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mforward\u001b[39m(\n\u001b[32m     59\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     60\u001b[39m     inputs: \u001b[38;5;28mdict\u001b[39m,\n\u001b[32m     61\u001b[39m     calc_criterion: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     62\u001b[39m ) -> \u001b[38;5;28mdict\u001b[39m:\n\u001b[32m     63\u001b[39m     (\n\u001b[32m     64\u001b[39m         imputed_data,\n\u001b[32m     65\u001b[39m         f_reconstruction,\n\u001b[32m     66\u001b[39m         b_reconstruction,\n\u001b[32m     67\u001b[39m         f_hidden_states,\n\u001b[32m     68\u001b[39m         b_hidden_states,\n\u001b[32m     69\u001b[39m         consistency_loss,\n\u001b[32m     70\u001b[39m         reconstruction_loss,\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m     results = {\n\u001b[32m     74\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mimputation\u001b[39m\u001b[33m\"\u001b[39m: imputed_data,\n\u001b[32m     75\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mconsistency_loss\u001b[39m\u001b[33m\"\u001b[39m: consistency_loss,\n\u001b[32m   (...)\u001b[39m\u001b[32m     79\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mb_reconstruction\u001b[39m\u001b[33m\"\u001b[39m: b_reconstruction,\n\u001b[32m     80\u001b[39m     }\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m calc_criterion:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/pypots/nn/modules/brits/backbone.py:253\u001b[39m, in \u001b[36mBackboneBRITS.forward\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    241\u001b[39m (\n\u001b[32m    242\u001b[39m     f_imputed_data,\n\u001b[32m    243\u001b[39m     f_reconstruction,\n\u001b[32m    244\u001b[39m     f_hidden_states,\n\u001b[32m    245\u001b[39m     f_reconstruction_loss,\n\u001b[32m    246\u001b[39m ) = \u001b[38;5;28mself\u001b[39m.rits_f(inputs, \u001b[33m\"\u001b[39m\u001b[33mforward\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    247\u001b[39m \u001b[38;5;66;03m# Results from the backward RITS.\u001b[39;00m\n\u001b[32m    248\u001b[39m (\n\u001b[32m    249\u001b[39m     b_imputed_data,\n\u001b[32m    250\u001b[39m     b_reconstruction,\n\u001b[32m    251\u001b[39m     b_hidden_states,\n\u001b[32m    252\u001b[39m     b_reconstruction_loss,\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m ) = \u001b[38;5;28mself\u001b[39m._reverse(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrits_b\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbackward\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m    255\u001b[39m imputed_data = (f_imputed_data + b_imputed_data) / \u001b[32m2\u001b[39m\n\u001b[32m    256\u001b[39m consistency_loss = \u001b[38;5;28mself\u001b[39m._get_consistency_loss(f_imputed_data, b_imputed_data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/pypots/nn/modules/brits/backbone.py:141\u001b[39m, in \u001b[36mBackboneRITS.forward\u001b[39m\u001b[34m(self, inputs, direction)\u001b[39m\n\u001b[32m    138\u001b[39m z_h = \u001b[38;5;28mself\u001b[39m.feat_reg(x_c)\n\u001b[32m    139\u001b[39m reconstruction_loss += \u001b[38;5;28mself\u001b[39m.training_loss(z_h, x, m)\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m alpha = torch.sigmoid(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcombining_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgamma_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    143\u001b[39m c_h = alpha * z_h + (\u001b[32m1\u001b[39m - alpha) * x_h\n\u001b[32m    144\u001b[39m reconstruction_loss += \u001b[38;5;28mself\u001b[39m.training_loss(c_h, x, m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "brits_results = brits.predict(dataset_for_testing)\n",
    "brits_imputation = brits_results[\"imputation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978a76bb",
   "metadata": {},
   "source": [
    "## US-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c3d498",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_gan_results = us_gan.predict(dataset_for_testing)\n",
    "us_gan_imputation = us_gan_results[\"imputation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf31562a",
   "metadata": {},
   "source": [
    "## GP-VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61d5315",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_vae_results = gp_vae.predict(dataset_for_testing)\n",
    "gp_vae_imputation = gp_vae_results[\"imputation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06db50d",
   "metadata": {},
   "source": [
    "## MRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1929bf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrnn_results = mrnn.predict(dataset_for_testing)\n",
    "mrnn_imputation = mrnn_results[\"imputation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f0f90a",
   "metadata": {},
   "source": [
    "# AE/MAE Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a91f0a",
   "metadata": {},
   "source": [
    "## SAITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68d61cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "saits_mae, saits_ae = calc_mae(\n",
    "    saits_imputation,\n",
    "    test_X_ori,\n",
    "    test_X_indicating_mask,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cc39b1",
   "metadata": {},
   "source": [
    "## BRITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b687dc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "brits_mae, brits_ae = calc_mae(\n",
    "    brits_imputation,\n",
    "    test_X_ori,\n",
    "    test_X_indicating_mask,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f632609",
   "metadata": {},
   "source": [
    "## US-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c599e4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "usgan_mae, usgan_ae = calc_mae(\n",
    "    us_gan_imputation,\n",
    "    test_X_ori,\n",
    "    test_X_indicating_mask,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fc6d39",
   "metadata": {},
   "source": [
    "## GP-VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118b1ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_vae_imputation = np.squeeze(gp_vae_imputation, axis=1)\n",
    "\n",
    "gpvae_mae, gpvae_ae = calc_mae(\n",
    "    gp_vae_imputation,\n",
    "    test_X_ori,\n",
    "    test_X_indicating_mask,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea203c34",
   "metadata": {},
   "source": [
    "## MRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a900e7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrnn_mae, mrnn_ae = calc_mae(\n",
    "    mrnn_imputation,\n",
    "    test_X_ori,\n",
    "    test_X_indicating_mask,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9a8341",
   "metadata": {},
   "source": [
    "# MAE Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ad5064",
   "metadata": {},
   "source": [
    "## SAITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c69424",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrnn_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9766af2",
   "metadata": {},
   "source": [
    "# Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38b06c9",
   "metadata": {},
   "source": [
    "## SAITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "411f008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "saits_ae = saits_ae.reshape(len(saits_ae) * 48 * 37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ab4a281",
   "metadata": {},
   "outputs": [],
   "source": [
    "saits_mask = test_X_indicating_mask.reshape(len(test_X_indicating_mask) * 48 * 37) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef56254b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_bootstrap_saits_general = toolkits.bootstrap_v3(saits_ae, saits_mask, 9000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176ba57d",
   "metadata": {},
   "source": [
    "#### Calculating lower bound and upper bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ffedd3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23768922914124652\n",
      "0.24450839648094444\n"
     ]
    }
   ],
   "source": [
    "lower_bounds_saits_general, upper_bounds_saits_general = toolkits.calc_lower_and_upper_bound_percentile(results_bootstrap_saits_general)\n",
    "\n",
    "print(lower_bounds_saits_general)\n",
    "print(upper_bounds_saits_general)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4f5d04",
   "metadata": {},
   "source": [
    "#### Mean values of lower bound and upper bound\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8fc060af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24109881281109546\n"
     ]
    }
   ],
   "source": [
    "mean_values_ci_saits_general = toolkits.calc_mean_values_ci(lower_bounds_saits_general, upper_bounds_saits_general)\n",
    "\n",
    "print(mean_values_ci_saits_general)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27846ee7",
   "metadata": {},
   "source": [
    "## BRITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b9710eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "brits_ae = brits_ae.reshape(len(brits_ae) * 48 * 37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a91359c",
   "metadata": {},
   "outputs": [],
   "source": [
    "brits_mask = test_X_indicating_mask.reshape(len(test_X_indicating_mask) * 48 * 37) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "202d27c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_bootstrap_brits_general = toolkits.bootstrap_v3(brits_ae, brits_mask, 9000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b04674",
   "metadata": {},
   "source": [
    "#### Calculating lower bound and upper bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d1417140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26245068951067047\n",
      "0.2793642862468709\n"
     ]
    }
   ],
   "source": [
    "lower_bounds_brits_general, upper_bounds_brits_general = toolkits.calc_lower_and_upper_bound_percentile(results_bootstrap_brits_general)\n",
    "\n",
    "print(lower_bounds_brits_general)\n",
    "print(upper_bounds_brits_general)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613884bc",
   "metadata": {},
   "source": [
    "#### Mean values of lower bound and upper bound\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92a1968c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27090748787877067\n"
     ]
    }
   ],
   "source": [
    "mean_values_ci_brits_general = toolkits.calc_mean_values_ci(lower_bounds_brits_general, upper_bounds_brits_general)\n",
    "\n",
    "print(mean_values_ci_brits_general)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e41be9b",
   "metadata": {},
   "source": [
    "## USGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be4b03a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "usgan_ae = usgan_ae.reshape(len(usgan_ae) * 48 * 37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "75a50224",
   "metadata": {},
   "outputs": [],
   "source": [
    "usgan_mask = test_X_indicating_mask.reshape(len(test_X_indicating_mask) * 48 * 37) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82a8344f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_bootstrap_usgan_general = toolkits.bootstrap_v3(usgan_ae, usgan_mask, 9000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed07bc8",
   "metadata": {},
   "source": [
    "#### Calculating lower bound and upper bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bab1ca5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2720592365951391\n",
      "0.28088690309217096\n"
     ]
    }
   ],
   "source": [
    "lower_bounds_usgan_general, upper_bounds_usgan_general = toolkits.calc_lower_and_upper_bound_percentile(results_bootstrap_usgan_general)\n",
    "\n",
    "print(lower_bounds_usgan_general)\n",
    "print(upper_bounds_usgan_general)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e5ce77",
   "metadata": {},
   "source": [
    "#### Mean values of lower bound and upper bound\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cce83a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27647306984365505\n"
     ]
    }
   ],
   "source": [
    "mean_values_ci_usgan_general = toolkits.calc_mean_values_ci(lower_bounds_usgan_general, upper_bounds_usgan_general)\n",
    "\n",
    "print(mean_values_ci_usgan_general)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d8bfcf",
   "metadata": {},
   "source": [
    "## GP-VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df11f6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpvae_ae = gpvae_ae.reshape(len(gpvae_ae)*48*37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "172ed29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpvae_mask = test_X_indicating_mask.reshape(len(test_X_indicating_mask) * 48 * 37) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f76169b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_bootstrap_gpvae_general = toolkits.bootstrap_v3(gpvae_ae, gpvae_mask, 9000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9bceca",
   "metadata": {},
   "source": [
    "#### Calculating lower bound and upper bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d7405475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44805537347509283\n",
      "0.4560020114360172\n"
     ]
    }
   ],
   "source": [
    "lower_bounds_gpvae_general, upper_bounds_gpvae_general = toolkits.calc_lower_and_upper_bound_percentile(results_bootstrap_gpvae_general)\n",
    "\n",
    "print(lower_bounds_gpvae_general)\n",
    "print(upper_bounds_gpvae_general)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7511fd4c",
   "metadata": {},
   "source": [
    "#### Mean values of lower bound and upper bound\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b2063831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.452028692455555\n"
     ]
    }
   ],
   "source": [
    "mean_values_ci_gpvae_general = toolkits.calc_mean_values_ci(lower_bounds_gpvae_general, upper_bounds_gpvae_general)\n",
    "\n",
    "print(mean_values_ci_gpvae_general)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0757468c",
   "metadata": {},
   "source": [
    "## MRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "edca0d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrnn_ae = mrnn_ae.reshape(len(mrnn_ae)*48*37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a30996cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrnn_mask = test_X_indicating_mask.reshape(len(test_X_indicating_mask) * 48 * 37) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bdd41d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_bootstrap_mrnn_general = toolkits.bootstrap_v3(mrnn_ae, mrnn_mask, 9000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dab7d2",
   "metadata": {},
   "source": [
    "#### Calculating lower bound and upper bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5335bbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6675308095955695\n",
      "0.6766626606979917\n"
     ]
    }
   ],
   "source": [
    "lower_bounds_mrnn_general, upper_bounds_mrnn_general = toolkits.calc_lower_and_upper_bound_percentile(results_bootstrap_mrnn_general)\n",
    "\n",
    "print(lower_bounds_mrnn_general)\n",
    "print(upper_bounds_mrnn_general)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d78ac4",
   "metadata": {},
   "source": [
    "#### Mean values of lower bound and upper bound\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6561282a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6720967351467806\n"
     ]
    }
   ],
   "source": [
    "mean_values_ci_mrnn_general = toolkits.calc_mean_values_ci(lower_bounds_mrnn_general, upper_bounds_mrnn_general)\n",
    "\n",
    "print(mean_values_ci_mrnn_general)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8597c380",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
